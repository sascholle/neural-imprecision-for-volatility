{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eea8180",
   "metadata": {},
   "source": [
    "## OPTIMISED MODEL FITTING \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e546ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from scipy.optimize import differential_evolution\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\", message=\"Glyph.*missing from font\")\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53476bd2",
   "metadata": {},
   "source": [
    "### Step 1: Task and environment generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bfccb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class VolatileBanditTask:\n",
    "    \"\"\"Container that stores a whole task instance for re-use across agents.\"\"\"\n",
    "    stimuli: np.ndarray  # here it is always zero but kept for completeness\n",
    "    latent_states: np.ndarray  # z_t, the true task-set index\n",
    "    switch_prob: np.ndarray  # τ_t\n",
    "    traps: np.ndarray  # Bernoulli noise on rewards\n",
    "    correct_actions: np.ndarray  # action that yields positive feedback if there is no trap\n",
    "    beta: float  # feedback reliability parameter η in the paper\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e32ff5",
   "metadata": {},
   "source": [
    "### Step 2: Particle filtering utilities - the sequential Monte Carlo (SMC) algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415710e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GLOBAL CONSTANTS (required by agent classes)\n",
    "# ============================================================\n",
    "K = 2  # Number of task-sets (latent states) in closed 2-armed bandit\n",
    "\n",
    "# TASK_MAPPING[stimulus] returns array of correct actions for each task-set\n",
    "# For closed environment: stimulus 0, task-set 0 -> action 0, task-set 1 -> action 1\n",
    "TASK_MAPPING = np.array([[0, 1]])  # Shape: (n_stimuli, K) = (1, 2)\n",
    "\n",
    "def stratified_resample(weights: np.ndarray, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Stratified resampling as used in the original C++ code.\"\"\"\n",
    "    n = len(weights)\n",
    "    cumulative = np.cumsum(weights)\n",
    "    positions = (rng.random(n) + np.arange(n)) / n\n",
    "    return np.searchsorted(cumulative, positions)\n",
    "\n",
    "\n",
    "def sample_inv_gamma(shape: float, scale: float, size: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Inverse-gamma sampler matching utils/useful_functions.py.\"\"\"\n",
    "    return scale / rng.gamma(shape, size=size)\n",
    "\n",
    "\n",
    "def logsumexp(log_w: np.ndarray) -> float:\n",
    "    b = np.max(log_w)\n",
    "    return b + np.log(np.sum(np.exp(log_w - b)))\n",
    "\n",
    "\n",
    "def normalise_log_weights(log_w: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Convert log-weights to normalized weights without numerical trouble.\"\"\"\n",
    "    log_w = log_w - logsumexp(log_w)\n",
    "    return np.exp(log_w)\n",
    "\n",
    "\n",
    "def compute_positive_states(mapping: np.ndarray, stimulus: int, action: int, reward: int) -> np.ndarray:\n",
    "    \"\"\"Replicates isEqual_and_adapted_logical_xor from the C++ helpers.\"\"\"\n",
    "    equals = mapping[stimulus] == action\n",
    "    if reward:  # reward==1 means the action was *reported* as correct\n",
    "        return equals.astype(float)\n",
    "    return (~equals).astype(float)\n",
    "\n",
    "\n",
    "def sample_new_state_excluding(current: int, gamma: np.ndarray, rng: np.random.Generator) -> int:\n",
    "    probs = gamma.copy()\n",
    "    probs[current] = 0.0\n",
    "    total = probs.sum()\n",
    "    if total == 0:\n",
    "        probs[:] = 1.0 / len(probs)\n",
    "    else:\n",
    "        probs /= total\n",
    "    return rng.choice(len(probs), p=probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc3d568",
   "metadata": {},
   "source": [
    "### Step 3a: Forward varying-volatility agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "249d6402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardVaryingVolatilityAgent:\n",
    "    \"\"\"Forward (online) SMC approximation of the exact varying-volatility model.\n",
    "    \n",
    "    Parameters (Paper vs Code mapping):\n",
    "    ------------------------------------\n",
    "    LATENT PARAMETERS (inferred by SMC):\n",
    "    - beta_samples (internal): η/2 sampled from Beta(1,1), transformed to η = beta/2 + 0.5\n",
    "      This is the FEEDBACK NOISE parameter (η > 0.5 in paper)\n",
    "    - nu_samples (internal): ν sampled from Inv-Gamma(3, 0.001)\n",
    "      This is the VOLATILITY VARIANCE parameter\n",
    "    - gamma_samples (internal): γ sampled from Dirichlet(1,...,1)\n",
    "      These are the task-set COMBINATION PROBABILITIES\n",
    "    \n",
    "    LATENT STATES (tracked by particle filter):\n",
    "    - state_particles: z_t, the current task-set hypothesis\n",
    "    - tau_particles: τ_t, the current volatility (switch probability)\n",
    "    \n",
    "    FREE PARAMETERS (for model fitting):\n",
    "    - beta_softmax: β, the softmax inverse temperature\n",
    "      NOTE: This is DIFFERENT from beta_samples (feedback noise η)!\n",
    "      When None, uses argmax policy (deterministic).\n",
    "    - epsilon_softmax: Lapse rate for random exploration\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_theta: int = 200, # simulation uses 1000, fitting only 200\n",
    "        num_state_particles: int = 200, # simulation uses 1000-2000, fitting o\n",
    "        tau_default: float = 0.03,\n",
    "        tau_bounds: Tuple[float, float] = (0.0, 1), # c++ code uses 0-1 even though this would be an extremely high volatile environment, but for Findling constistency - kept the same. \n",
    "        beta_prior: Tuple[float, float] = (1.0, 1.0),\n",
    "        nu_prior: Tuple[float, float] = (3.0, 1e-3),\n",
    "        gamma_prior: float = 1.0,\n",
    "        ess_threshold: float = 0.5,\n",
    "        beta_softmax: Optional[float] = 1.0,  # None in simulation for argmax policy\n",
    "        epsilon_softmax: float = 0.0,\n",
    "        seed: Optional[int] = None,\n",
    "    ):\n",
    "        self.num_theta = num_theta\n",
    "        self.num_state_particles = num_state_particles\n",
    "        self.tau_default = tau_default\n",
    "        self.tau_bounds = tau_bounds\n",
    "        self.beta_prior = beta_prior\n",
    "        self.nu_prior = nu_prior\n",
    "        self.gamma_prior = gamma_prior\n",
    "        self.ess_threshold = ess_threshold\n",
    "        self.beta_softmax = beta_softmax\n",
    "        self.epsilon_softmax = epsilon_softmax\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "        self._init_particles()\n",
    "\n",
    "    def _init_particles(self):\n",
    "        self.beta_samples = self.rng.beta(\n",
    "            self.beta_prior[0], self.beta_prior[1], size=self.num_theta\n",
    "        )\n",
    "        self.nu_samples = sample_inv_gamma(\n",
    "            self.nu_prior[0], self.nu_prior[1], size=self.num_theta, rng=self.rng\n",
    "        )\n",
    "        self.gamma_samples = self.rng.dirichlet(\n",
    "            np.ones(K) * self.gamma_prior, size=self.num_theta\n",
    "        )\n",
    "        self.state_particles = self.rng.integers(\n",
    "            K, size=(self.num_theta, self.num_state_particles)\n",
    "        )\n",
    "        self.tau_particles = np.full(\n",
    "            (self.num_theta, self.num_state_particles), self.tau_default\n",
    "        )\n",
    "        self.log_theta_weights = np.zeros(self.num_theta)\n",
    "        self.theta_weights = np.ones(self.num_theta) / self.num_theta\n",
    "        self.pending_observation = None\n",
    "        self.current_action = None\n",
    "        self.current_stimulus = None\n",
    "        self.trial_index = 0\n",
    "\n",
    "        self.history = {\n",
    "            \"vol_mean\": [],\n",
    "            \"beta_mean\": [],\n",
    "            \"nu_mean\": [],\n",
    "            \"ts_prob\": [],\n",
    "        }\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Agent interaction API\n",
    "    # ------------------------------------------------------------------\n",
    "    def act(self, stimulus: int) -> Tuple[int, np.ndarray]:\n",
    "        self._maybe_smc_update()\n",
    "        action_probs = self._action_distribution(stimulus)\n",
    "        action = self._sample_action(action_probs)\n",
    "        self.current_action = action\n",
    "        self.current_stimulus = stimulus\n",
    "        return action, action_probs\n",
    "\n",
    "    def observe(self, reward: int):\n",
    "        self.pending_observation = (\n",
    "            self.current_stimulus,\n",
    "            self.current_action,\n",
    "            reward,\n",
    "        )\n",
    "        self.trial_index += 1\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # SMC internals\n",
    "    # ------------------------------------------------------------------\n",
    "    def _maybe_smc_update(self):\n",
    "        if self.pending_observation is None:\n",
    "            return\n",
    "\n",
    "        stimulus, action, reward = self.pending_observation\n",
    "        prev_states = self.state_particles.copy()\n",
    "        prev_taus = self.tau_particles.copy()\n",
    "\n",
    "        positive_states = compute_positive_states(TASK_MAPPING, stimulus, action, reward)\n",
    "        # Transform beta from [0,1] to [0.5,1] as in original code: betaSamples/2 + 0.5\n",
    "        # This ensures feedback noise η > 0.5 (reward is more likely when action is correct)\n",
    "        beta_transformed = self.beta_samples / 2.0 + 0.5\n",
    "        beta_matrix = beta_transformed[:, None]\n",
    "        state_pos = positive_states[prev_states]\n",
    "        likelihoods = state_pos * beta_matrix + (1 - state_pos) * (1 - beta_matrix)\n",
    "        likelihoods = np.clip(likelihoods, 1e-9, None)\n",
    "\n",
    "        sum_weights = likelihoods.sum(axis=1)\n",
    "        self.log_theta_weights += np.log(sum_weights / self.num_state_particles)\n",
    "        weights_norm = likelihoods / sum_weights[:, None]\n",
    "\n",
    "        new_states = np.empty_like(prev_states)\n",
    "        new_taus = np.empty_like(prev_taus)\n",
    "        for theta_idx in range(self.num_theta):\n",
    "            ancestor_idx = stratified_resample(weights_norm[theta_idx], self.rng)\n",
    "            new_states[theta_idx] = prev_states[theta_idx, ancestor_idx]\n",
    "            new_taus[theta_idx] = prev_taus[theta_idx, ancestor_idx]\n",
    "\n",
    "        noise = self.rng.normal(\n",
    "            0.0,\n",
    "            np.sqrt(self.nu_samples)[:, None],\n",
    "            size=new_taus.shape,\n",
    "        )\n",
    "        tau_candidates = np.clip(\n",
    "            new_taus + noise, self.tau_bounds[0], self.tau_bounds[1]\n",
    "        )\n",
    "        self.tau_particles = tau_candidates\n",
    "\n",
    "        switch_mask = self.rng.random(size=new_states.shape) < tau_candidates\n",
    "        propagated_states = new_states.copy()\n",
    "        for theta_idx in range(self.num_theta):\n",
    "            gamma = self.gamma_samples[theta_idx]\n",
    "            indices = np.where(switch_mask[theta_idx])[0]\n",
    "            for idx in indices:\n",
    "                propagated_states[theta_idx, idx] = sample_new_state_excluding(\n",
    "                    propagated_states[theta_idx, idx], gamma, self.rng\n",
    "                )\n",
    "        self.state_particles = propagated_states\n",
    "\n",
    "        self.pending_observation = None\n",
    "        self.theta_weights = normalise_log_weights(self.log_theta_weights)\n",
    "        self._maybe_rejuvenate()\n",
    "        self._record_history()\n",
    "\n",
    "    def _maybe_rejuvenate(self):\n",
    "        ess = 1.0 / np.sum(self.theta_weights ** 2)\n",
    "        if ess >= self.ess_threshold * self.num_theta:\n",
    "            return\n",
    "\n",
    "        beta_mu = np.sum(self.theta_weights * self.beta_samples)\n",
    "        beta_var = np.sum(self.theta_weights * (self.beta_samples - beta_mu) ** 2)\n",
    "        beta_var = max(beta_var, 1e-6)\n",
    "        beta_alpha = max(((1 - beta_mu) / beta_var - 1 / beta_mu) * beta_mu ** 2, 1.0)\n",
    "        beta_beta = max(beta_alpha * (1 / beta_mu - 1), 1.0)\n",
    "\n",
    "        nu_mu = np.sum(self.theta_weights * self.nu_samples)\n",
    "        nu_var = np.sum(self.theta_weights * (self.nu_samples - nu_mu) ** 2)\n",
    "        nu_var = max(nu_var, 1e-6)\n",
    "        nu_alpha = nu_mu ** 2 / nu_var + 2.0\n",
    "        nu_beta = nu_mu * (nu_alpha - 1)\n",
    "\n",
    "        dirichlet_means = np.sum(\n",
    "            self.theta_weights[:, None] * self.gamma_samples, axis=0\n",
    "        )\n",
    "        dirichlet_vars = np.sum(\n",
    "            self.theta_weights[:, None] * (self.gamma_samples ** 2), axis=0\n",
    "        ) - dirichlet_means ** 2\n",
    "        dirichlet_vars = np.clip(dirichlet_vars, 1e-6, None)\n",
    "        dirichlet_precision = (\n",
    "            np.sum(dirichlet_means - dirichlet_means ** 2) / np.sum(dirichlet_vars)\n",
    "        ) - 1\n",
    "        dirichlet_precision = max(dirichlet_precision, 1.0)\n",
    "        dirichlet_params = np.maximum(\n",
    "            dirichlet_means * dirichlet_precision, 1.0\n",
    "        )\n",
    "\n",
    "        self.beta_samples = self.rng.beta(\n",
    "            beta_alpha, beta_beta, size=self.num_theta\n",
    "        )\n",
    "        self.nu_samples = sample_inv_gamma(\n",
    "            nu_alpha, nu_beta, size=self.num_theta, rng=self.rng\n",
    "        )\n",
    "        self.gamma_samples = self.rng.dirichlet(\n",
    "            dirichlet_params, size=self.num_theta\n",
    "        )\n",
    "        self.log_theta_weights[:] = 0.0\n",
    "        self.theta_weights = np.ones(self.num_theta) / self.num_theta\n",
    "\n",
    "    def _record_history(self):\n",
    "        tau_means = self.tau_particles.mean(axis=1)\n",
    "        vol_mean = np.sum(self.theta_weights * tau_means)\n",
    "        beta_mean = np.sum(self.theta_weights * self.beta_samples)\n",
    "        nu_mean = np.sum(self.theta_weights * self.nu_samples)\n",
    "        ts_prob = self._taskset_probability(self.theta_weights)\n",
    "\n",
    "        self.history[\"vol_mean\"].append(vol_mean)\n",
    "        self.history[\"beta_mean\"].append(beta_mean)\n",
    "        self.history[\"nu_mean\"].append(nu_mean)\n",
    "        self.history[\"ts_prob\"].append(ts_prob)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Decision policy helpers\n",
    "    # ------------------------------------------------------------------\n",
    "    def _taskset_probability(self, theta_weights: np.ndarray) -> np.ndarray:\n",
    "        ts_prob = np.zeros(K)\n",
    "        for theta_idx in range(self.num_theta):\n",
    "            counts = np.bincount(\n",
    "                self.state_particles[theta_idx], minlength=K\n",
    "            ) / self.num_state_particles\n",
    "            ts_prob += theta_weights[theta_idx] * counts\n",
    "        ts_prob /= np.sum(ts_prob)\n",
    "        return ts_prob\n",
    "\n",
    "    def _action_distribution(self, stimulus: int) -> np.ndarray:\n",
    "        ts_prob = self._taskset_probability(self.theta_weights)\n",
    "        action_probs = np.zeros(2)\n",
    "        for action in range(2):\n",
    "            mask = TASK_MAPPING[stimulus] == action\n",
    "            action_probs[action] = ts_prob[mask].sum()\n",
    "        if self.beta_softmax is None:\n",
    "            greedy_action = np.argmax(action_probs)\n",
    "            probs = np.zeros_like(action_probs)\n",
    "            probs[greedy_action] = 1.0\n",
    "            return probs\n",
    "        # Findling et al.: softmax on LOG of beliefs, not raw probabilities\n",
    "        # P(a) ∝ exp(β * log(belief_a)) = belief_a^β\n",
    "        log_beliefs = np.log(np.clip(action_probs, 1e-10, 1.0))\n",
    "        logits = log_beliefs * self.beta_softmax\n",
    "        logits -= np.max(logits)  # Numerical stability\n",
    "        probs = np.exp(logits)\n",
    "        probs /= probs.sum()\n",
    "        probs = probs * (1 - self.epsilon_softmax) + self.epsilon_softmax / len(probs)\n",
    "        return probs\n",
    "\n",
    "    def _sample_action(self, action_probs: np.ndarray) -> int:\n",
    "        if np.isclose(action_probs.sum(), 0):\n",
    "            return self.rng.integers(2)\n",
    "        if np.count_nonzero(action_probs) == 1:\n",
    "            return int(np.argmax(action_probs))\n",
    "        return self.rng.choice(len(action_probs), p=action_probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad88ae",
   "metadata": {},
   "source": [
    "### Step 3b: Weber-imprecision agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608743de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeberImprecisionAgent:\n",
    "    \"\"\"Forward Weber-imprecision agent.\n",
    "    \n",
    "    Parameters (Paper vs Code mapping):\n",
    "    ------------------------------------\n",
    "    - beta_samples (internal): η/2 sampled from Beta(1,1), transformed to η = beta/2 + 0.5\n",
    "      This is the FEEDBACK NOISE parameter (η > 0.5)\n",
    "    - gamma_samples (internal): γ sampled from Dirichlet(1,...,1)\n",
    "      These are the task-set COMBINATION PROBABILITIES\n",
    "    - lambdaa: λ, the Weber scaling factor (FREE PARAMETER)\n",
    "    - mu: μ, the Weber baseline noise (FREE PARAMETER). C++ default is 0.0!\n",
    "    - beta_softmax: β, the softmax inverse temperature (FREE PARAMETER)\n",
    "      NOTE: This is DIFFERENT from beta_samples (feedback noise η)!\n",
    "    \n",
    "    Weber noise formula: ε_t ~ U(0, μ + λ*d_t), applied as ε_t/2\n",
    "    \n",
    "    NOTE: Weber does NOT have nu_samples or tau_particles - those are VarVol only!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_theta: int = 200, # simulation uses 1000, fitting only 200\n",
    "        num_state_particles: int = 200, # simulation uses 1000-2000, fitting only 200\n",
    "        lambdaa: float = 0.4,      # C++ default for simulation 0.9, TO FIT 0.4\n",
    "        mu: float = 0.1,           # C++ default for simulation 0.0, TO FIT 0.1\n",
    "        beta_prior: Tuple[float, float] = (1.0, 1.0),\n",
    "        gamma_prior: float = 1.0,\n",
    "        ess_threshold: float = 0.5,\n",
    "        beta_softmax: Optional[float] = 1.0,  # None = argmax policy in simulation\n",
    "        epsilon_softmax: float = 0.0,\n",
    "        seed: Optional[int] = None,\n",
    "    ):\n",
    "        self.num_theta = num_theta\n",
    "        self.num_state_particles = num_state_particles\n",
    "        self.lambdaa = lambdaa\n",
    "        self.mu = mu\n",
    "        self.beta_prior = beta_prior\n",
    "        self.gamma_prior = gamma_prior\n",
    "        self.ess_threshold = ess_threshold\n",
    "        self.beta_softmax = beta_softmax\n",
    "        self.epsilon_softmax = epsilon_softmax\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "        self._init_particles()\n",
    "\n",
    "    def _init_particles(self):\n",
    "        self.beta_samples = self.rng.beta(\n",
    "            self.beta_prior[0], self.beta_prior[1], size=self.num_theta\n",
    "        )\n",
    "        self.gamma_samples = self.rng.dirichlet(\n",
    "            np.ones(K) * self.gamma_prior, size=self.num_theta\n",
    "        )\n",
    "        self.state_particles = self.rng.integers(\n",
    "            K, size=(self.num_theta, self.num_state_particles)\n",
    "        )\n",
    "        self.log_theta_weights = np.zeros(self.num_theta)\n",
    "        self.theta_weights = np.ones(self.num_theta) / self.num_theta\n",
    "        self.pending_observation = None\n",
    "        self.current_action = None\n",
    "        self.current_stimulus = None\n",
    "\n",
    "        self.history = {\n",
    "            \"epsilon\": [],\n",
    "            \"beta_mean\": [],\n",
    "            \"ts_prob\": [],\n",
    "        }\n",
    "\n",
    "    def act(self, stimulus: int) -> Tuple[int, np.ndarray]:\n",
    "        self._maybe_smc_update()\n",
    "        action_probs = self._action_distribution(stimulus)\n",
    "        action = self._sample_action(action_probs)\n",
    "        self.current_action = action\n",
    "        self.current_stimulus = stimulus\n",
    "        return action, action_probs\n",
    "\n",
    "    def observe(self, reward: int):\n",
    "        self.pending_observation = (\n",
    "            self.current_stimulus,\n",
    "            self.current_action,\n",
    "            reward,\n",
    "        )\n",
    "\n",
    "    def _maybe_smc_update(self):\n",
    "        if self.pending_observation is None:\n",
    "            return\n",
    "\n",
    "        stimulus, action, reward = self.pending_observation\n",
    "        prev_states = self.state_particles.copy()\n",
    "\n",
    "        positive_states = compute_positive_states(TASK_MAPPING, stimulus, action, reward)\n",
    "        beta_transformed = self.beta_samples / 2.0 + 0.5\n",
    "        beta_matrix = beta_transformed[:, None]\n",
    "        state_pos = positive_states[prev_states]\n",
    "        likelihoods = state_pos * beta_matrix + (1 - state_pos) * (1 - beta_matrix)\n",
    "        likelihoods = np.clip(likelihoods, 1e-9, None)\n",
    "\n",
    "        # Compute ante (before update) belief\n",
    "        ante_counts = (\n",
    "            np.apply_along_axis(\n",
    "                lambda row: np.bincount(row, minlength=K), 1, prev_states\n",
    "            )\n",
    "            / self.num_state_particles\n",
    "        )\n",
    "        \n",
    "        sum_weights = likelihoods.sum(axis=1)\n",
    "        weights_norm = likelihoods / sum_weights[:, None]\n",
    "        \n",
    "        # Compute post (after update) belief per theta\n",
    "        weighted_post = np.zeros_like(ante_counts)\n",
    "        for theta_idx in range(self.num_theta):\n",
    "            for state_idx in range(self.num_state_particles):\n",
    "                s = prev_states[theta_idx, state_idx]\n",
    "                weighted_post[theta_idx, s] += weights_norm[theta_idx, state_idx]\n",
    "        weighted_post = np.divide(\n",
    "            weighted_post,\n",
    "            weighted_post.sum(axis=1, keepdims=True) + 1e-12,\n",
    "        )\n",
    "        \n",
    "        # === GLOBAL DISTANCE (matching C++) ===\n",
    "        current_theta_weights = normalise_log_weights(self.log_theta_weights)\n",
    "        global_ante = np.sum(current_theta_weights[:, None] * ante_counts, axis=0)\n",
    "        \n",
    "        updated_log_weights = self.log_theta_weights + np.log(sum_weights / self.num_state_particles)\n",
    "        updated_theta_weights = normalise_log_weights(updated_log_weights)\n",
    "        global_post = np.sum(updated_theta_weights[:, None] * weighted_post, axis=0)\n",
    "        \n",
    "        global_distance = np.sum(np.abs(global_ante - global_post))\n",
    "        epsilon = (self.lambdaa * global_distance + self.mu) / 2.0\n",
    "        epsilon = np.clip(epsilon, 0.0, 0.5)\n",
    "        \n",
    "        self.history[\"epsilon\"].append(epsilon)\n",
    "\n",
    "        self.log_theta_weights += np.log(sum_weights / self.num_state_particles)\n",
    "\n",
    "        new_states = np.empty_like(prev_states)\n",
    "        for theta_idx in range(self.num_theta):\n",
    "            ancestor_idx = stratified_resample(weights_norm[theta_idx], self.rng)\n",
    "            candidates = prev_states[theta_idx, ancestor_idx]\n",
    "            keep_mask = self.rng.random(self.num_state_particles) > epsilon  # Single epsilon\n",
    "            for s_idx in range(self.num_state_particles):\n",
    "                if keep_mask[s_idx]:\n",
    "                    new_states[theta_idx, s_idx] = candidates[s_idx]\n",
    "                else:\n",
    "                    if K == 2:\n",
    "                        new_states[theta_idx, s_idx] = 1 - candidates[s_idx]\n",
    "                    else:\n",
    "                        new_states[theta_idx, s_idx] = sample_new_state_excluding(\n",
    "                            candidates[s_idx], self.gamma_samples[theta_idx], self.rng\n",
    "                        )\n",
    "        self.state_particles = new_states\n",
    "\n",
    "        self.pending_observation = None\n",
    "        self.theta_weights = normalise_log_weights(self.log_theta_weights)\n",
    "        self._maybe_rejuvenate()\n",
    "        self._record_history()\n",
    "\n",
    "    def _maybe_rejuvenate(self):\n",
    "        ess = 1.0 / np.sum(self.theta_weights ** 2)\n",
    "        if ess >= self.ess_threshold * self.num_theta:\n",
    "            return\n",
    "\n",
    "        beta_mu = np.sum(self.theta_weights * self.beta_samples)\n",
    "        beta_var = np.sum(self.theta_weights * (self.beta_samples - beta_mu) ** 2)\n",
    "        beta_var = max(beta_var, 1e-6)\n",
    "        beta_alpha = max(((1 - beta_mu) / beta_var - 1 / beta_mu) * beta_mu ** 2, 1.0)\n",
    "        beta_beta = max(beta_alpha * (1 / beta_mu - 1), 1.0)\n",
    "\n",
    "        dirichlet_means = np.sum(\n",
    "            self.theta_weights[:, None] * self.gamma_samples, axis=0\n",
    "        )\n",
    "        dirichlet_vars = np.sum(\n",
    "            self.theta_weights[:, None] * (self.gamma_samples ** 2), axis=0\n",
    "        ) - dirichlet_means ** 2\n",
    "        dirichlet_vars = np.clip(dirichlet_vars, 1e-6, None)\n",
    "        dirichlet_precision = (\n",
    "            np.sum(dirichlet_means - dirichlet_means ** 2) / np.sum(dirichlet_vars)\n",
    "        ) - 1\n",
    "        dirichlet_precision = max(dirichlet_precision, 1.0)\n",
    "        dirichlet_params = np.maximum(\n",
    "            dirichlet_means * dirichlet_precision, 1.0\n",
    "        )\n",
    "\n",
    "        self.beta_samples = self.rng.beta(\n",
    "            beta_alpha, beta_beta, size=self.num_theta\n",
    "        )\n",
    "        # Weber does NOT have nu_samples - only beta and gamma!\n",
    "        self.gamma_samples = self.rng.dirichlet(\n",
    "            dirichlet_params, size=self.num_theta\n",
    "        )\n",
    "        self.log_theta_weights[:] = 0.0\n",
    "        self.theta_weights = np.ones(self.num_theta) / self.num_theta\n",
    "\n",
    "    def _record_history(self):\n",
    "        beta_mean = np.sum(self.theta_weights * self.beta_samples)\n",
    "        ts_prob = self._taskset_probability()\n",
    "        self.history[\"beta_mean\"].append(beta_mean)\n",
    "        self.history[\"ts_prob\"].append(ts_prob)\n",
    "\n",
    "    def _taskset_probability(self) -> np.ndarray:\n",
    "        ts_prob = np.zeros(K)\n",
    "        for theta_idx in range(self.num_theta):\n",
    "            counts = np.bincount(\n",
    "                self.state_particles[theta_idx], minlength=K\n",
    "            ) / self.num_state_particles\n",
    "            ts_prob += self.theta_weights[theta_idx] * counts\n",
    "        ts_prob /= np.sum(ts_prob)\n",
    "        return ts_prob\n",
    "\n",
    "    def _action_distribution(self, stimulus: int) -> np.ndarray:\n",
    "        ts_prob = self._taskset_probability()\n",
    "        action_probs = np.zeros(2)\n",
    "        for action in range(2):\n",
    "            mask = TASK_MAPPING[stimulus] == action\n",
    "            action_probs[action] = ts_prob[mask].sum()\n",
    "        if self.beta_softmax is None:\n",
    "            greedy_action = np.argmax(action_probs)\n",
    "            probs = np.zeros_like(action_probs)\n",
    "            probs[greedy_action] = 1.0\n",
    "            return probs\n",
    "        # Findling et al.: softmax on LOG of beliefs, not raw probabilities\n",
    "        # P(a) ∝ exp(β * log(belief_a)) = belief_a^β\n",
    "        log_beliefs = np.log(np.clip(action_probs, 1e-10, 1.0))\n",
    "        logits = log_beliefs * self.beta_softmax\n",
    "        logits -= np.max(logits)  # Numerical stability\n",
    "        probs = np.exp(logits)\n",
    "        probs /= probs.sum()\n",
    "        probs = probs * (1 - self.epsilon_softmax) + self.epsilon_softmax / len(probs)\n",
    "        return probs\n",
    "\n",
    "    def _sample_action(self, action_probs: np.ndarray) -> int:\n",
    "        if np.isclose(action_probs.sum(), 0):\n",
    "            return self.rng.integers(2)\n",
    "        if np.count_nonzero(action_probs) == 1:\n",
    "            return int(np.argmax(action_probs))\n",
    "        return self.rng.choice(len(action_probs), p=action_probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d28063",
   "metadata": {},
   "source": [
    "### Step 4: Parameter Fitting\n",
    "\n",
    "Settings for fitting:\n",
    "\n",
    "We use Differential Evolution instead of Bayesian Optimization like in Findling - for speed. \n",
    "\n",
    "Findling et al. (2021) used:\n",
    "   - EXACT models: 1000 theta × 1000 state = 1M particles \n",
    "   - FORWARD models: 200 theta × 200 state = 40K particles \n",
    "\n",
    " For a seminar project 100×100 is used for efficiency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "150861b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " FITTING SETTINGS\n",
      "======================================================================\n",
      "Particles: 100 x 100 = 10,000\n",
      "PF runs per evaluation: 10\n",
      "DE settings: maxiter=15, popsize=5, tol=0.1\n",
      "Parallel workers: 20 (of 22 cores)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "# FITTING SETTINGS - DIFFERENTIAL EVOLUTION\n",
    "\n",
    "# Particle filter settings\n",
    "FITTING_N_THETA = 100\n",
    "FITTING_N_STATE = 100\n",
    "\n",
    "# PF runs for likelihood estimation (marginalization)\n",
    "N_PF_RUNS = 10  # Average over this many PF realizations per evaluation\n",
    "\n",
    "# Differential Evolution settings (tuned from test: 9 min per participant)\n",
    "DE_MAXITER = 15          # Generations\n",
    "DE_POPSIZE = 5           # Population size multiplier (actual pop = popsize * n_params)\n",
    "DE_TOL = 0.1             # Convergence tolerance\n",
    "DE_SEED = 42             # Reproducibility\n",
    "\n",
    "# Parallelization\n",
    "N_WORKERS = max(1, os.cpu_count() - 2)  # Leave 2 cores free\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" FITTING SETTINGS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Particles: {FITTING_N_THETA} x {FITTING_N_STATE} = {FITTING_N_THETA * FITTING_N_STATE:,}\")\n",
    "print(f\"PF runs per evaluation: {N_PF_RUNS}\")\n",
    "print(f\"DE settings: maxiter={DE_MAXITER}, popsize={DE_POPSIZE}, tol={DE_TOL}\")\n",
    "print(f\"Parallel workers: {N_WORKERS} (of {os.cpu_count()} cores)\")\n",
    "\n",
    "# ============================================================\n",
    "# Reconstruct task from human data\n",
    "# ============================================================\n",
    "def reconstruct_task_from_human_data(participant_df: pd.DataFrame) -> Tuple[VolatileBanditTask, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Reconstruct a VolatileBanditTask from human behavioral data.\n",
    "    \n",
    "    KEY FIELDS USED:\n",
    "    ----------------\n",
    "    - hidden_state: Which arm was correct on each trial (0 or 1)\n",
    "      → This IS the latent state AND the correct action (identity mapping)\n",
    "      → Switches are encoded here: [0,0,0,1,1,1,...] means switch at trial 3\n",
    "    \n",
    "    - false_feedback: Whether feedback was flipped (trap) on each trial\n",
    "      → True means human saw opposite of what they should have\n",
    "    \n",
    "    - outcome: The actual reward the human received (\"win\" or \"loss\")\n",
    "      → This is what we feed to the agent during fitting!\n",
    "    \n",
    "    FIELDS NOT USED IN FITTING (just for bookkeeping):\n",
    "    --------------------------------------------------\n",
    "    - stimuli: Always 0 (2-armed bandit has 1 stimulus type)\n",
    "    - switch_prob: Average switch rate (not used - we have exact switches)\n",
    "    - beta: Average trap rate (not used - we have exact traps)\n",
    "    \n",
    "    Returns:\n",
    "        task: VolatileBanditTask with exact trial-by-trial structure\n",
    "        human_rewards: The actual rewards the human received (0 or 1)\n",
    "    \"\"\"\n",
    "    n_trials = len(participant_df)\n",
    "    \n",
    "    # Extract exact trial-by-trial data (not averages!)\n",
    "    correct_actions = participant_df['hidden_state'].values.astype(int)\n",
    "    traps = participant_df['false_feedback'].values.astype(bool)\n",
    "    \n",
    "    # The ACTUAL reward the human saw (what we feed to the agent!)\n",
    "    human_rewards = (participant_df['outcome'] == 'win').values.astype(int)\n",
    "    \n",
    "    # These are for bookkeeping only - not used in fitting\n",
    "    switches = np.sum(np.diff(correct_actions) != 0)\n",
    "    switch_rate = switches / (n_trials - 1) if n_trials > 1 else 0.0\n",
    "    switch_prob = np.full(n_trials, switch_rate) #unused\n",
    "    trap_rate = np.mean(traps)\n",
    "    beta = 1.0 - trap_rate # unused\n",
    "    \n",
    "    # Create task with trial-by-trial data\n",
    "    stimuli = np.zeros(n_trials, dtype=int)\n",
    "    latent_states = correct_actions.copy()\n",
    "    \n",
    "    task = VolatileBanditTask(\n",
    "        stimuli=stimuli,\n",
    "        latent_states=latent_states,\n",
    "        switch_prob=switch_prob, # not used in determinstic human task\n",
    "        traps=traps,\n",
    "        correct_actions=correct_actions,\n",
    "        beta=beta,\n",
    "    )\n",
    "    \n",
    "    return task, human_rewards\n",
    "\n",
    "# ============================================================\n",
    "# Negative Log-Likelihood functions (to minimize)\n",
    "# ============================================================\n",
    "# Following Findling et al. (2021):\n",
    "#   - VarVol: 1 free parameter (β = inverse temperature)\n",
    "#   - Weber:  3 free parameters (β, μ, λ)\n",
    "#\n",
    "# We average over multiple PF realizations to get stable likelihood estimates\n",
    "# (equivalent to Findling's numberOfBetaSamples marginalization)\n",
    "\n",
    "def compute_neg_log_likelihood_varvol(params, task, human_choices, human_rewards, n_runs=N_PF_RUNS*2):\n",
    "    \"\"\"\n",
    "    Compute negative log-likelihood for VarVol model.\n",
    "    Averages over n_runs particle filter realizations for stability.\n",
    "    \n",
    "    params: [beta_softmax]\n",
    "    \"\"\"\n",
    "    beta_softmax = params[0]\n",
    "    beta_softmax = max(0.01, beta_softmax)\n",
    "    \n",
    "    log_liks = []\n",
    "    for run_seed in range(n_runs):\n",
    "        try:\n",
    "            agent = ForwardVaryingVolatilityAgent(\n",
    "                num_theta=FITTING_N_THETA,\n",
    "                num_state_particles=FITTING_N_STATE,\n",
    "                beta_softmax=beta_softmax,\n",
    "                seed=42 + run_seed  # Different seed each run\n",
    "            )\n",
    "            \n",
    "            log_lik = 0.0\n",
    "            for t in range(len(human_choices)):\n",
    "                stimulus = task.stimuli[t]\n",
    "                _, action_probs = agent.act(stimulus)\n",
    "                \n",
    "                human_choice = human_choices[t]\n",
    "                prob_human_choice = np.clip(action_probs[human_choice], 1e-10, 1.0)\n",
    "                log_lik += np.log(prob_human_choice)\n",
    "                \n",
    "                agent.current_action = human_choice\n",
    "                agent.current_stimulus = stimulus\n",
    "                agent.observe(human_rewards[t])\n",
    "            \n",
    "            log_liks.append(log_lik)\n",
    "        except Exception as e:\n",
    "            log_liks.append(-1e8)  # Large negative on error\n",
    "    \n",
    "    # Average over PF realizations (marginalization)\n",
    "    mean_log_lik = np.mean(log_liks)\n",
    "    return -mean_log_lik  # Negative because we minimize\n",
    "\n",
    "\n",
    "def compute_neg_log_likelihood_weber(params, task, human_choices, human_rewards, n_runs=N_PF_RUNS):\n",
    "    \"\"\"\n",
    "    Compute negative log-likelihood for Weber model.\n",
    "    Averages over n_runs particle filter realizations for stability.\n",
    "    \n",
    "    params: [beta_softmax, lambdaa, mu]\n",
    "    \"\"\"\n",
    "    beta_softmax, lambdaa, mu = params\n",
    "    beta_softmax = max(0.01, beta_softmax)\n",
    "    lambdaa = np.clip(lambdaa, 0.01, 2.0)\n",
    "    mu = np.clip(mu, 0.0, 1.0)\n",
    "    \n",
    "    log_liks = []\n",
    "    for run_seed in range(n_runs):\n",
    "        try:\n",
    "            agent = WeberImprecisionAgent(\n",
    "                num_theta=FITTING_N_THETA,\n",
    "                num_state_particles=FITTING_N_STATE,\n",
    "                beta_softmax=beta_softmax,\n",
    "                lambdaa=lambdaa,\n",
    "                mu=mu,\n",
    "                seed=42 + run_seed  # Different seed each run\n",
    "            )\n",
    "            \n",
    "            log_lik = 0.0\n",
    "            for t in range(len(human_choices)):\n",
    "                stimulus = task.stimuli[t]\n",
    "                _, action_probs = agent.act(stimulus)\n",
    "                \n",
    "                human_choice = human_choices[t]\n",
    "                prob_human_choice = np.clip(action_probs[human_choice], 1e-10, 1.0)\n",
    "                log_lik += np.log(prob_human_choice)\n",
    "                \n",
    "                agent.current_action = human_choice\n",
    "                agent.current_stimulus = stimulus\n",
    "                agent.observe(human_rewards[t])\n",
    "            \n",
    "            log_liks.append(log_lik)\n",
    "        except Exception as e:\n",
    "            log_liks.append(-1e8)\n",
    "    \n",
    "    mean_log_lik = np.mean(log_liks)\n",
    "    return -mean_log_lik # Negative because we minimize\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FITTING FUNCTIONS: DIFFERENTIAL EVOLUTION\n",
    "# ============================================================\n",
    "# DE is a global optimizer - it does NOT need multiple restarts like L-BFGS-B.\n",
    "# It maintains a population of candidate solutions and evolves them,\n",
    "# inherently exploring the full parameter space.\n",
    "\n",
    "def fit_varvol_to_participant(task, human_choices, human_rewards):\n",
    "    \"\"\"\n",
    "    Fit VarVol model using Differential Evolution.\n",
    "    VarVol has 1 free parameter: beta (softmax inverse temperature)\n",
    "    \"\"\"\n",
    "    bounds = [(0.1, 15.0)]  # beta_softmax\n",
    "    \n",
    "    result = differential_evolution(\n",
    "        compute_neg_log_likelihood_varvol,\n",
    "        bounds,\n",
    "        args=(task, human_choices, human_rewards),\n",
    "        seed=DE_SEED,\n",
    "        maxiter=DE_MAXITER,\n",
    "        popsize=DE_POPSIZE,\n",
    "        tol=DE_TOL,\n",
    "        workers=1,  # Do not parallelize internally (we parallelize across participants)\n",
    "        updating='deferred',\n",
    "        disp=False\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'beta_softmax': result.x[0],\n",
    "        'neg_log_lik': result.fun,\n",
    "        'log_lik': -result.fun,\n",
    "        'success': result.success,\n",
    "        'n_params': 1,\n",
    "        'n_evals': result.nfev\n",
    "    }\n",
    "\n",
    "\n",
    "def fit_weber_to_participant(task, human_choices, human_rewards):\n",
    "    \"\"\"\n",
    "    Fit Weber model using Differential Evolution.\n",
    "    Weber has 3 free parameters: beta (softmax), lambda (Weber scaling), mu (baseline noise)\n",
    "    \n",
    "    DE will properly explore the lambda and mu parameter space,\n",
    "    unlike L-BFGS-B which got stuck at starting values.\n",
    "    \"\"\"\n",
    "    bounds = [\n",
    "        (0.1, 15.0),   # beta_softmax\n",
    "        (0.0, 2.0),    # lambdaa (Weber scaling)\n",
    "        (0.0, 1.0)     # mu (baseline noise)\n",
    "    ]\n",
    "    \n",
    "    result = differential_evolution(\n",
    "        compute_neg_log_likelihood_weber,\n",
    "        bounds,\n",
    "        args=(task, human_choices, human_rewards),\n",
    "        seed=DE_SEED,\n",
    "        maxiter=DE_MAXITER,\n",
    "        popsize=DE_POPSIZE,\n",
    "        tol=DE_TOL,\n",
    "        workers=1,  # Do not parallelize internally\n",
    "        updating='deferred',\n",
    "        disp=False\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'beta_softmax': result.x[0],\n",
    "        'lambdaa': result.x[1],\n",
    "        'mu': result.x[2],\n",
    "        'neg_log_lik': result.fun,\n",
    "        'log_lik': -result.fun,\n",
    "        'success': result.success,\n",
    "        'n_params': 3,\n",
    "        'n_evals': result.nfev\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0c4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " MLE PARAMETER FITTING: Differential Evolution\n",
      "======================================================================\n",
      "\n",
      "Found 45 participants\n",
      "Estimated time: ~20 minutes with 20 workers\n",
      "\n",
      "Starting parallel fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PARALLEL FITTING WITH DIFFERENTIAL EVOLUTION\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" MLE PARAMETER FITTING: Differential Evolution\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "DATA_DIR = Path('2.fitting_data/extended_csvs')\n",
    "CSV_FILES = sorted(DATA_DIR.glob('*.csv'))\n",
    "\n",
    "print(f\"\\nFound {len(CSV_FILES)} participants\")\n",
    "print(f\"Estimated time: ~{len(CSV_FILES) * 9 / N_WORKERS:.0f} minutes with {N_WORKERS} workers\")\n",
    "\n",
    "\n",
    "def fit_one_participant(csv_file):\n",
    "    \"\"\"Fit both models to one participant using Differential Evolution.\"\"\"\n",
    "    participant_id = csv_file.stem\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        required_cols = ['hidden_state', 'false_feedback', 'outcome', 'userChoice']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            return None\n",
    "\n",
    "        task, human_rewards = reconstruct_task_from_human_data(df)\n",
    "        human_choices = df['userChoice'].values.astype(int)\n",
    "        n_trials = len(human_choices)\n",
    "\n",
    "        # Fit VarVol with DE\n",
    "        varvol_fit = fit_varvol_to_participant(task, human_choices, human_rewards)\n",
    "        \n",
    "        # Fit Weber with DE\n",
    "        weber_fit = fit_weber_to_participant(task, human_choices, human_rewards)\n",
    "\n",
    "        # Compute BIC: k * ln(n) + 2 * NLL\n",
    "        varvol_bic = varvol_fit['n_params'] * np.log(n_trials) + 2 * varvol_fit['neg_log_lik']\n",
    "        weber_bic = weber_fit['n_params'] * np.log(n_trials) + 2 * weber_fit['neg_log_lik']\n",
    "\n",
    "        return {\n",
    "            'participant_id': participant_id,\n",
    "            'n_trials': n_trials,\n",
    "            # VarVol results\n",
    "            'varvol_beta_softmax': varvol_fit['beta_softmax'],\n",
    "            'varvol_log_lik': varvol_fit['log_lik'],\n",
    "            'varvol_bic': varvol_bic,\n",
    "            'varvol_n_params': varvol_fit['n_params'],\n",
    "            'varvol_success': varvol_fit['success'],\n",
    "            'varvol_n_evals': varvol_fit['n_evals'],\n",
    "            # Weber results\n",
    "            'weber_beta_softmax': weber_fit['beta_softmax'],\n",
    "            'weber_lambdaa': weber_fit['lambdaa'],\n",
    "            'weber_mu': weber_fit['mu'],\n",
    "            'weber_log_lik': weber_fit['log_lik'],\n",
    "            'weber_bic': weber_bic,\n",
    "            'weber_n_params': weber_fit['n_params'],\n",
    "            'weber_success': weber_fit['success'],\n",
    "            'weber_n_evals': weber_fit['n_evals'],\n",
    "            # Comparison\n",
    "            'delta_bic': varvol_bic - weber_bic,\n",
    "            'better_model': 'VarVol' if varvol_bic < weber_bic else 'Weber',\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error {participant_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RUN PARALLEL FITTING\n",
    "# ============================================================\n",
    "print(f\"\\nStarting parallel fitting...\")\n",
    "start_time = time.time()\n",
    "\n",
    "results = Parallel(n_jobs=N_WORKERS, verbose=10)(\n",
    "    delayed(fit_one_participant)(csv_file) for csv_file in CSV_FILES\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "# Filter failures\n",
    "results = [r for r in results if r is not None]\n",
    "fitting_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" FITTING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Time: {elapsed/60:.1f} minutes ({elapsed/3600:.2f} hours)\")\n",
    "print(f\"Avg per participant: {elapsed/len(fitting_df):.1f} seconds\")\n",
    "print(f\"Successfully fitted: {len(fitting_df)}/{len(CSV_FILES)}\")\n",
    "\n",
    "# Save results\n",
    "output_path = Path('2.fitting_data/mle_fitting_results_DE.csv')\n",
    "fitting_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nSaved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e23815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted parameters:\n",
      "                          participant_id  varvol_beta_softmax  \\\n",
      "0   25da8b12-9a43-40cd-84f2-5b152a5f0f7f             0.250018   \n",
      "1                  adaptive_lab_07ee303f             1.629521   \n",
      "2                  adaptive_lab_08d9887c             2.079174   \n",
      "3                  adaptive_lab_09b45851             0.415455   \n",
      "4                  adaptive_lab_1671e99c             1.372539   \n",
      "5                  adaptive_lab_1ea56ad2             3.367573   \n",
      "6                  adaptive_lab_22a6875c             0.610808   \n",
      "7                  adaptive_lab_2eade079             2.501466   \n",
      "8                  adaptive_lab_3162592a             1.130284   \n",
      "9                  adaptive_lab_390371f9             0.010000   \n",
      "10                 adaptive_lab_42003269             1.195727   \n",
      "11                 adaptive_lab_4b7a6ad7             1.203803   \n",
      "12                 adaptive_lab_52ae4c1c             0.010000   \n",
      "13                 adaptive_lab_534d2332             0.383759   \n",
      "14                 adaptive_lab_57523f00             0.554014   \n",
      "15                 adaptive_lab_62d173ea             0.025168   \n",
      "16                 adaptive_lab_685a115e             0.010000   \n",
      "17                 adaptive_lab_6bfae065             0.129552   \n",
      "18                 adaptive_lab_6efcb881             2.461419   \n",
      "19                 adaptive_lab_7791e665             0.348007   \n",
      "20                 adaptive_lab_7ba35dc6             0.598579   \n",
      "21                 adaptive_lab_7ebadc2b             0.631923   \n",
      "22                 adaptive_lab_8003f702             0.636816   \n",
      "23                 adaptive_lab_8b1d2fbe             2.874525   \n",
      "24                 adaptive_lab_8eb0859e             0.605553   \n",
      "25                 adaptive_lab_9d4ed4c8             0.584220   \n",
      "26                 adaptive_lab_a474f8ac             2.139815   \n",
      "27                 adaptive_lab_a55bffe3             0.862497   \n",
      "28                 adaptive_lab_aed15edd             0.312006   \n",
      "29                 adaptive_lab_afa823e9             1.537036   \n",
      "30                 adaptive_lab_baac83df             2.291995   \n",
      "31                 adaptive_lab_c5b3641b             1.507675   \n",
      "32                 adaptive_lab_c88395a3             2.125156   \n",
      "33                 adaptive_lab_c973295f             1.250618   \n",
      "34                 adaptive_lab_cc508b71             0.761818   \n",
      "35                 adaptive_lab_cd4434f6             0.770550   \n",
      "36                 adaptive_lab_ceb36f8b             0.365143   \n",
      "37                 adaptive_lab_d3b198e4             1.969216   \n",
      "38                 adaptive_lab_d3df5afa             1.307089   \n",
      "39                 adaptive_lab_d8fc8189             0.754204   \n",
      "40                 adaptive_lab_e97713f3             1.924104   \n",
      "41                 adaptive_lab_eef00ebf             1.131833   \n",
      "42                 adaptive_lab_ef0d7ba0             1.744211   \n",
      "43                 adaptive_lab_f2d405ab             0.992575   \n",
      "44                 adaptive_lab_f69d4496             1.687734   \n",
      "\n",
      "    weber_beta_softmax  weber_lambdaa  weber_mu  varvol_log_lik  weber_log_lik  \n",
      "0             0.350579       0.900000  0.000000      -68.975513     -68.445919  \n",
      "1             2.102080       0.900000  0.000000      -38.508977     -39.323590  \n",
      "2             1.305939       0.900000  0.000000      -42.819298     -56.413094  \n",
      "3             0.495230       0.900000  0.000000      -65.859522     -66.036613  \n",
      "4             1.970686       0.900000  0.000000      -44.140864     -39.371807  \n",
      "5             4.551111       0.775670  0.017451      -18.919881     -19.958276  \n",
      "6             0.897751       0.900000  0.000000      -65.652908     -64.593085  \n",
      "7             3.579205       0.900000  0.000000      -37.058613     -28.227163  \n",
      "8             1.371824       0.900000  0.000000      -48.004706     -48.267514  \n",
      "9             0.010000       0.497484  0.566607      -69.407295     -69.319680  \n",
      "10            1.582087       0.900000  0.000000      -55.378847     -50.430205  \n",
      "11            1.770016       0.900000  0.000000      -47.577305     -45.027946  \n",
      "12            0.010000       1.178042  0.859664      -69.313688     -69.314951  \n",
      "13            0.608278       0.900000  0.000000      -64.981180     -64.031886  \n",
      "14            0.957608       0.024091  0.284526      -66.424325     -64.162895  \n",
      "15            0.186410       0.130287  0.458951      -69.300487     -69.118130  \n",
      "16            0.010000       1.634638  0.691470      -69.377482     -69.315084  \n",
      "17            0.317291       0.900000  0.000000      -69.034077     -68.286621  \n",
      "18            2.199426       0.900000  0.000000      -34.997391     -43.892233  \n",
      "19            0.356223       0.900000  0.000000      -65.956283     -67.522480  \n",
      "20            0.719677       0.900000  0.000000      -62.282821     -62.262188  \n",
      "21            0.803431       0.900000  0.000000      -56.054797     -59.097796  \n",
      "22            2.322675       0.540966  0.344029      -64.284725     -57.477591  \n",
      "23            2.409094       0.159447  0.148542      -19.694466     -21.537638  \n",
      "24            0.906878       0.900000  0.000000      -55.197269     -55.983924  \n",
      "25            4.514812       0.504149  0.474747      -60.165626     -53.198200  \n",
      "26            2.219838       0.900000  0.000000      -41.900219     -47.783012  \n",
      "27            1.665813       0.140267  0.353622      -56.586132     -53.879755  \n",
      "28            0.505256       0.900000  0.000000      -66.278635     -65.012424  \n",
      "29            1.932566       0.900000  0.000000      -57.222222     -51.071353  \n",
      "30            2.628864       0.900000  0.000000      -41.424743     -36.081266  \n",
      "31            1.919508       0.900000  0.000000      -47.836458     -44.478994  \n",
      "32            8.507283       1.420373  0.002254      -51.962961     -31.352597  \n",
      "33            1.620263       0.900000  0.000000      -53.818992     -53.067750  \n",
      "34            1.265883       0.900000  0.000000      -57.696245     -55.547395  \n",
      "35            1.214894       0.900000  0.000000      -57.633365     -53.590271  \n",
      "36            0.664590       0.900000  0.000000      -66.933010     -64.274407  \n",
      "37           13.547483       0.900000  0.000000      -31.990625      -7.379151  \n",
      "38            2.101546       0.900000  0.197393      -64.179048     -60.219987  \n",
      "39            1.163958       0.899999  0.000000      -55.683431     -54.912943  \n",
      "40            2.579331       0.900000  0.000000      -28.352952     -35.075331  \n",
      "41            0.998211       0.664762  0.049031      -48.603121     -55.689704  \n",
      "42            2.630394       0.900000  0.000000      -30.556585     -32.445594  \n",
      "43            2.054109       0.391374  0.179890      -53.846331     -48.107206  \n",
      "44            2.137317       0.900000  0.000000      -34.783122     -38.257435  \n"
     ]
    }
   ],
   "source": [
    "print(\"Fitted parameters:\")\n",
    "fitting_df = pd.read_csv('2.fitting_data/mle_fitting_results_DE.csv')\n",
    "print(fitting_df[['participant_id', 'varvol_beta_softmax', 'weber_beta_softmax', \n",
    "                   'weber_lambdaa', 'weber_mu', 'varvol_log_lik', 'weber_log_lik']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005aebec",
   "metadata": {},
   "source": [
    "### Step 5: Summary and Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b31044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RESULTS SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" MLE FITTING RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "n_participants = len(fitting_df)\n",
    "n_varvol_wins = (fitting_df['better_model'] == 'VarVol').sum()\n",
    "n_weber_wins = (fitting_df['better_model'] == 'Weber').sum()\n",
    "\n",
    "print(f\"\\nParticipants fitted: {n_participants}\")\n",
    "print(f\"VarVol wins (lower BIC): {n_varvol_wins} ({100*n_varvol_wins/n_participants:.1f}%)\")\n",
    "print(f\"Weber wins (lower BIC):  {n_weber_wins} ({100*n_weber_wins/n_participants:.1f}%)\")\n",
    "\n",
    "print(f\"\\n{'Metric':<25} {'VarVol':<15} {'Weber':<15}\")\n",
    "print(\"-\"*55)\n",
    "print(f\"{'Mean Log-Likelihood':<25} {fitting_df['varvol_log_lik'].mean():<15.2f} {fitting_df['weber_log_lik'].mean():<15.2f}\")\n",
    "print(f\"{'Mean BIC':<25} {fitting_df['varvol_bic'].mean():<15.2f} {fitting_df['weber_bic'].mean():<15.2f}\")\n",
    "print(f\"{'Sum BIC':<25} {fitting_df['varvol_bic'].sum():<15.2f} {fitting_df['weber_bic'].sum():<15.2f}\")\n",
    "\n",
    "delta_bic_mean = fitting_df['delta_bic'].mean()\n",
    "delta_bic_sum = fitting_df['delta_bic'].sum()\n",
    "\n",
    "print(f\"\\n{'Mean ΔBIC (VV-Weber)':<25} {delta_bic_mean:<15.2f}\")\n",
    "print(f\"{'Sum ΔBIC (VV-Weber)':<25} {delta_bic_sum:<15.2f}\")\n",
    "\n",
    "if delta_bic_sum < 0:\n",
    "    print(f\"\\n--> Overall: VarVol is favored (sum ΔBIC = {delta_bic_sum:.1f})\")\n",
    "else:\n",
    "    print(f\"\\n--> Overall: Weber is favored (sum ΔBIC = {delta_bic_sum:.1f})\")\n",
    "\n",
    "# Fitted parameter distributions\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" FITTED PARAMETER DISTRIBUTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nVarVol (1 free param):\")\n",
    "print(f\"  beta: mean={fitting_df['varvol_beta_softmax'].mean():.2f}, \"\n",
    "      f\"std={fitting_df['varvol_beta_softmax'].std():.2f}, \"\n",
    "      f\"range=[{fitting_df['varvol_beta_softmax'].min():.2f}, {fitting_df['varvol_beta_softmax'].max():.2f}]\")\n",
    "\n",
    "print(f\"\\nWeber (3 free params):\")\n",
    "print(f\"  beta:   mean={fitting_df['weber_beta_softmax'].mean():.2f}, \"\n",
    "      f\"std={fitting_df['weber_beta_softmax'].std():.2f}, \"\n",
    "      f\"range=[{fitting_df['weber_beta_softmax'].min():.2f}, {fitting_df['weber_beta_softmax'].max():.2f}]\")\n",
    "print(f\"  lambda: mean={fitting_df['weber_lambdaa'].mean():.2f}, \"\n",
    "      f\"std={fitting_df['weber_lambdaa'].std():.2f}, \"\n",
    "      f\"range=[{fitting_df['weber_lambdaa'].min():.2f}, {fitting_df['weber_lambdaa'].max():.2f}]\")\n",
    "print(f\"  mu:     mean={fitting_df['weber_mu'].mean():.3f}, \"\n",
    "      f\"std={fitting_df['weber_mu'].std():.3f}, \"\n",
    "      f\"range=[{fitting_df['weber_mu'].min():.3f}, {fitting_df['weber_mu'].max():.3f}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" FITTED PARAMETERS PER PARTICIPANT\")\n",
    "print(\"=\"*70)\n",
    "print(fitting_df[['participant_id', 'varvol_beta_softmax', 'weber_beta_softmax', \n",
    "                  'weber_lambdaa', 'weber_mu', 'delta_bic', 'better_model']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb090dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SANITY CHECK: Did DE actually explore lambda and mu?\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" SANITY CHECK: Weber Parameter Exploration\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nWeber lambda distribution:\")\n",
    "print(f\"   Mean:  {fitting_df['weber_lambdaa'].mean():.3f}\")\n",
    "print(f\"   Std:   {fitting_df['weber_lambdaa'].std():.3f}\")\n",
    "print(f\"   Min:   {fitting_df['weber_lambdaa'].min():.3f}\")\n",
    "print(f\"   Max:   {fitting_df['weber_lambdaa'].max():.3f}\")\n",
    "\n",
    "print(f\"\\nWeber mu distribution:\")\n",
    "print(f\"   Mean:  {fitting_df['weber_mu'].mean():.3f}\")\n",
    "print(f\"   Std:   {fitting_df['weber_mu'].std():.3f}\")\n",
    "print(f\"   Min:   {fitting_df['weber_mu'].min():.3f}\")\n",
    "print(f\"   Max:   {fitting_df['weber_mu'].max():.3f}\")\n",
    "\n",
    "# Check if parameters are stuck (the problem we fixed!)\n",
    "lambda_stuck = fitting_df['weber_lambdaa'].std() < 0.05\n",
    "mu_stuck = fitting_df['weber_mu'].std() < 0.02\n",
    "\n",
    "if lambda_stuck or mu_stuck:\n",
    "    print(\"\\n[WARNING] Parameters may still be stuck!\")\n",
    "    if lambda_stuck:\n",
    "        print(f\"   lambda has very low variance (std={fitting_df['weber_lambdaa'].std():.3f})\")\n",
    "    if mu_stuck:\n",
    "        print(f\"   mu has very low variance (std={fitting_df['weber_mu'].std():.3f})\")\n",
    "else:\n",
    "    print(\"\\n[OK] Parameters show healthy variation - DE is working!\")\n",
    "\n",
    "# Show unique values to verify exploration\n",
    "n_unique_lambda = fitting_df['weber_lambdaa'].nunique()\n",
    "n_unique_mu = fitting_df['weber_mu'].nunique()\n",
    "\n",
    "print(f\"\\nUnique lambda values: {n_unique_lambda} (should be close to {len(fitting_df)})\")\n",
    "print(f\"Unique mu values: {n_unique_mu} (should be close to {len(fitting_df)})\")\n",
    "\n",
    "# Compare to old stuck values\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Comparison to L-BFGS-B stuck values:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"Old stuck lambda=0.9: {(fitting_df['weber_lambdaa'] == 0.9).sum()} participants\")\n",
    "print(f\"Old stuck mu=0.0:     {(fitting_df['weber_mu'] == 0.0).sum()} participants\")\n",
    "\n",
    "if (fitting_df['weber_lambdaa'] == 0.9).sum() > len(fitting_df) * 0.5:\n",
    "    print(\"\\n[WARNING] Many participants still have lambda=0.9 - check DE settings!\")\n",
    "else:\n",
    "    print(\"\\n[OK] DE successfully moved away from stuck values!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10121009",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VISUALIZATION: BIC and Log-Likelihood per participant\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "fig.suptitle('Model Comparison: BIC and Accuracy', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Panel 1: BIC per participant\n",
    "ax = axes[0]\n",
    "x = np.arange(len(fitting_df))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, fitting_df['varvol_bic'], width, label='VarVol', color=\"#6eaaa2\", alpha=0.8)\n",
    "ax.bar(x + width/2, fitting_df['weber_bic'], width, label='Weber', color=\"#d27763\", alpha=0.8)\n",
    "ax.set_xlabel('Participant')\n",
    "ax.set_ylabel('BIC (lower = better)')\n",
    "ax.set_title('BIC per Participant')\n",
    "ax.legend()\n",
    "ax.set_xticks(x[::5])\n",
    "\n",
    "# Panel 2: Log-likelihood per participant\n",
    "ax = axes[1]\n",
    "ax.bar(x - width/2, fitting_df['varvol_log_lik'], width, label='VarVol', color=\"#6eaaa2\", alpha=0.8)\n",
    "ax.bar(x + width/2, fitting_df['weber_log_lik'], width, label='Weber', color=\"#d27763\", alpha=0.8)\n",
    "ax.set_xlabel('Participant')\n",
    "ax.set_ylabel('Log-Likelihood (higher = better)')\n",
    "ax.set_title('Log-Likelihood per Participant')\n",
    "ax.legend()\n",
    "ax.set_xticks(x[::5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Panel 3: Pie Count wins\n",
    "n_varvol_wins = (fitting_df['delta_bic'] < 0).sum()\n",
    "n_weber_wins = (fitting_df['delta_bic'] >= 0).sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "colors = [\"#6eaaa2\", \"#d27763\"]\n",
    "explode = (0.05, 0.05)\n",
    "ax.pie([n_varvol_wins, n_weber_wins],\n",
    "       labels=[f'VarVol\\n({n_varvol_wins})', f'Weber\\n({n_weber_wins})'],\n",
    "       autopct='%1.1f%%', colors=colors, explode=explode,\n",
    "       shadow=True, startangle=90)\n",
    "ax.set_title('Model Wins (BIC)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f567b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter distributions\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.suptitle('Fitted Parameter Distributions', fontsize=14, fontweight='bold')\n",
    "\n",
    "# β distribution\n",
    "ax = axes[0]\n",
    "ax.hist(fitting_df['varvol_beta_softmax'], bins=15, alpha=0.7, label='VarVol β', color=\"#6eaaa2\")\n",
    "ax.hist(fitting_df['weber_beta_softmax'], bins=15, alpha=0.7, label='Weber β', color=\"#d27763\")\n",
    "ax.set_xlabel('β (inverse temperature)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Softmax β Distribution')\n",
    "ax.legend()\n",
    "\n",
    "# λ distribution\n",
    "ax = axes[1]\n",
    "ax.hist(fitting_df['weber_lambdaa'], bins=15, color=\"#d27763\", alpha=0.7, edgecolor='black')\n",
    "ax.axvline(fitting_df['weber_lambdaa'].mean(), color='black', linestyle='--', linewidth=2,\n",
    "           label=f'Mean: {fitting_df['weber_lambdaa'].mean():.2f}')\n",
    "ax.set_xlabel('λ (Weber scaling)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Weber λ Distribution')\n",
    "ax.legend()\n",
    "\n",
    "# μ distribution\n",
    "ax = axes[2]\n",
    "ax.hist(fitting_df['weber_mu'], bins=15, color=\"#d27763\", alpha=0.7, edgecolor='black')\n",
    "ax.axvline(fitting_df['weber_mu'].mean(), color='black', linestyle='--', linewidth=2,\n",
    "           label=f'Mean: {fitting_df['weber_mu'].mean():.3f}')\n",
    "ax.set_xlabel('μ (baseline noise)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Weber μ Distribution')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629c0b37",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fitting_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m N_SEEDS = \u001b[32m5\u001b[39m\n\u001b[32m      3\u001b[39m choice_match_results = []\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfitting_df\u001b[49m.iterrows():\n\u001b[32m      6\u001b[39m     participant_id = row[\u001b[33m'\u001b[39m\u001b[33mparticipant_id\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      7\u001b[39m     csv_file = DATA_DIR / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparticipant_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'fitting_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Choice match rates (model vs human) - seed variance analysis\n",
    "\n",
    "# Small seed test: average over 5 seeds for each participant\n",
    "N_SEEDS = 5\n",
    "choice_match_results = []\n",
    "\n",
    "for i, row in fitting_df.iterrows():\n",
    "    participant_id = row['participant_id']\n",
    "    csv_file = DATA_DIR / f\"{participant_id}.csv\"\n",
    "    if not csv_file.exists():\n",
    "        continue\n",
    "    df = pd.read_csv(csv_file)\n",
    "    task, human_rewards = reconstruct_task_from_human_data(df)\n",
    "    human_choices = df['userChoice'].values.astype(int)\n",
    "    n_trials = len(human_choices)\n",
    "\n",
    "    varvol_matches = []\n",
    "    weber_matches = []\n",
    "    for seed in range(N_SEEDS):\n",
    "        varvol_agent = ForwardVaryingVolatilityAgent(\n",
    "            num_theta=FITTING_N_THETA,\n",
    "            num_state_particles=FITTING_N_STATE,\n",
    "            beta_softmax=row['varvol_beta_softmax'],\n",
    "            seed=seed\n",
    "        )\n",
    "        weber_agent = WeberImprecisionAgent(\n",
    "            num_theta=FITTING_N_THETA,\n",
    "            num_state_particles=FITTING_N_STATE,\n",
    "            beta_softmax=row['weber_beta_softmax'],\n",
    "            lambdaa=row['weber_lambdaa'],\n",
    "            mu=row['weber_mu'],\n",
    "            seed=seed\n",
    "        )\n",
    "        varvol_choices = []\n",
    "        weber_choices = []\n",
    "        for t in range(n_trials):\n",
    "            stimulus = task.stimuli[t]\n",
    "            vv_action, _ = varvol_agent.act(stimulus)\n",
    "            varvol_choices.append(vv_action)\n",
    "            varvol_agent.current_action = human_choices[t]\n",
    "            varvol_agent.current_stimulus = stimulus\n",
    "            varvol_agent.observe(human_rewards[t])\n",
    "            wb_action, _ = weber_agent.act(stimulus)\n",
    "            weber_choices.append(wb_action)\n",
    "            weber_agent.current_action = human_choices[t]\n",
    "            weber_agent.current_stimulus = stimulus\n",
    "            weber_agent.observe(human_rewards[t])\n",
    "        varvol_matches.append(np.mean(np.array(varvol_choices) == human_choices))\n",
    "        weber_matches.append(np.mean(np.array(weber_choices) == human_choices))\n",
    "\n",
    "    choice_match_results.append({\n",
    "        'participant_id': participant_id,\n",
    "        'varvol_match_mean': np.mean(varvol_matches),\n",
    "        'varvol_match_std': np.std(varvol_matches),\n",
    "        'weber_match_mean': np.mean(weber_matches),\n",
    "        'weber_match_std': np.std(weber_matches)\n",
    "    })\n",
    "\n",
    "\n",
    "match_df = pd.DataFrame(choice_match_results)\n",
    "\n",
    "print(\"Seed variance summary (averaged across all participants):\")\n",
    "print(f\"VarVol: mean match={match_df['varvol_match_mean'].mean():.3f}, mean seed std={match_df['varvol_match_std'].mean():.3f}\")\n",
    "print(f\"Weber:  mean match={match_df['weber_match_mean'].mean():.3f}, mean seed std={match_df['weber_match_std'].mean():.3f}\")\n",
    "\n",
    "# Boxplot of choice match rates across participants\n",
    "data_to_plot = [match_df['varvol_match_mean'], match_df['weber_match_mean']]\n",
    "labels = ['VarVol', 'Weber']\n",
    "colors = [\"#6eaaa2\", \"#d27763\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "bp = ax.boxplot(data_to_plot, patch_artist=True, labels=labels)\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "ax.set_ylabel('Choice Match Rate')\n",
    "ax.set_title('Model-Human Choice Match Rate Across Participants (Seed-Averaged)')\n",
    "ax.set_ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # Add condition info\n",
    "# condition_info = {}\n",
    "# for csv_file in sorted(DATA_DIR.glob('*.csv')):\n",
    "#     try:\n",
    "#         participant_id = csv_file.stem\n",
    "#         df = pd.read_csv(csv_file)\n",
    "#         instruction = df['instructionCondition'].iloc[0]\n",
    "#         noise = df['condition'].mode()[0] if 'condition' in df.columns else 'unknown'\n",
    "#         condition_info[participant_id] = {\n",
    "#             'instruction': instruction,\n",
    "#             'noise': noise\n",
    "#         }\n",
    "#     except Exception as e:\n",
    "#         pass\n",
    "\n",
    "# match_df['instruction'] = match_df['participant_id'].map(lambda x: condition_info.get(x, {}).get('instruction', 'unknown'))\n",
    "# match_df['noise'] = match_df['participant_id'].map(lambda x: condition_info.get(x, {}).get('noise', 'unknown'))\n",
    "\n",
    "# conditions = sorted(match_df[['instruction', 'noise']].drop_duplicates().values.tolist())\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# labels = []\n",
    "# vv_data = []\n",
    "# wb_data = []\n",
    "# for c in conditions:\n",
    "#     if c[0] != 'unknown':\n",
    "#         subset = match_df[(match_df['instruction']==c[0]) & (match_df['noise']==c[1])]\n",
    "#         vv_data.append(subset['varvol_match_human'].values)\n",
    "#         wb_data.append(subset['weber_match_human'].values)\n",
    "#         labels.append(f\"{c[0]}-{c[1]}\")\n",
    "\n",
    "# bp1 = ax.boxplot(vv_data, positions=np.arange(len(labels))-0.2, widths=0.3, patch_artist=True, labels=labels)\n",
    "# bp2 = ax.boxplot(wb_data, positions=np.arange(len(labels))+0.2, widths=0.3, patch_artist=True)\n",
    "# for patch in bp1['boxes']:\n",
    "#     patch.set_facecolor(\"#6eaaa2\")\n",
    "#     patch.set_alpha(0.7)\n",
    "# for patch in bp2['boxes']:\n",
    "#     patch.set_facecolor(\"#d27763\")\n",
    "#     patch.set_alpha(0.7)\n",
    "# ax.set_ylabel('Choice Match Rate')\n",
    "# ax.set_title('Choice Match Rate by Condition')\n",
    "# ax.set_xticks(np.arange(len(labels)))\n",
    "# ax.set_xticklabels(labels, rotation=30)\n",
    "# ax.legend([bp1[\"boxes\"][0], bp2[\"boxes\"][0]], ['VarVol', 'Weber'])\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4900002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human accuracy per group \n",
    "\n",
    "block_accuracy_results = []\n",
    "\n",
    "for csv_file in sorted(DATA_DIR.glob('*.csv')):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    participant_id = csv_file.stem\n",
    "    instruction = df['instructionCondition'].iloc[0]\n",
    "    blocks = df['block'].unique()\n",
    "    for block in blocks:\n",
    "        block_df = df[df['block'] == block]\n",
    "        noise = block_df['condition'].iloc[0] if 'condition' in block_df.columns else 'unknown'\n",
    "        human_choices = block_df['userChoice'].values.astype(int)\n",
    "        correct_actions = block_df['hidden_state'].values.astype(int)\n",
    "        human_accuracy = np.mean(human_choices == correct_actions)\n",
    "        block_accuracy_results.append({\n",
    "            'participant_id': participant_id,\n",
    "            'instruction': instruction,\n",
    "            'noise': noise,\n",
    "            'block': block,\n",
    "            'human_accuracy': human_accuracy\n",
    "        })\n",
    "\n",
    "block_acc_df = pd.DataFrame(block_accuracy_results)\n",
    "\n",
    "# Group by instruction and noise\n",
    "groups = sorted(block_acc_df[['instruction', 'noise']].drop_duplicates().values.tolist())\n",
    "labels = []\n",
    "data = []\n",
    "for g in groups:\n",
    "    if g[0] != 'unknown' and g[1] != 'unknown':\n",
    "        subset = block_acc_df[(block_acc_df['instruction']==g[0]) & (block_acc_df['noise']==g[1])]\n",
    "        data.append(subset['human_accuracy'].values)\n",
    "        labels.append(f\"{g[0]}-{g[1]}\")\n",
    "        print('check the block subsets. should be 2 blocks per participant so 90 in total?')\n",
    "        print(f\"{g[0]}-{g[1]}: {len(subset)} blocks\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "bp = ax.boxplot(data, patch_artist=True, labels=labels)\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor(\"#cccccc\")\n",
    "    patch.set_alpha(0.7)\n",
    "ax.set_ylabel('Human Accuracy')\n",
    "ax.set_title('Human Accuracy by Instruction and Noise (Block-Level)')\n",
    "ax.set_xticks(np.arange(1, len(labels)+1))\n",
    "ax.set_xticklabels(labels, rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd75dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.cpu_count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webermodelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
