{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e546ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Glyph.*missing from font\")\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53476bd2",
   "metadata": {},
   "source": [
    "### Step 1: Task and environment generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bfccb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class VolatileBanditTask:\n",
    "    \"\"\"Container that stores a whole task instance for re-use across agents.\"\"\"\n",
    "    stimuli: np.ndarray  # here it is always zero but kept for completeness\n",
    "    latent_states: np.ndarray  # z_t, the true task-set index\n",
    "    switch_prob: np.ndarray  # œÑ_t\n",
    "    traps: np.ndarray  # Bernoulli noise on rewards\n",
    "    correct_actions: np.ndarray  # action that yields positive feedback if there is no trap\n",
    "    beta: float  # feedback reliability parameter Œ∑ in the paper\n",
    "\n",
    "\n",
    "def generate_bandit_task(\n",
    "    trial_num: int = 200,\n",
    "    tau_min: float = 0.0,    # Paper: œÑ ‚àà [0, 0.5]\n",
    "    tau_max: float = 0.5,    # Paper: œÑ ‚àà [0, 0.5]\n",
    "    nu: float = 1e-4,        # Constant within a block; model infers it via Inv-Gamma(3, 0.001) prior\n",
    "    beta: float = 0.9,       # Œ∑ (feedback reliability); model infers via Œ∑/2 ~ Beta(1,1) ‚Üí Œ∑ ‚àà [0.5,1]\n",
    "    seed: Optional[int] = None,\n",
    ") -> VolatileBanditTask:\n",
    "    \"\"\"Generate a single task trajectory following Findling et al. (2021) Methods.\n",
    "\n",
    "    Paper specification:\n",
    "    - œÑ_t varies as bounded Gaussian random walk in [0, 0.5] with variance ŒΩ\n",
    "    - ŒΩ is constant within a block (model has Inv-Gamma(3, 0.001) prior)\n",
    "    - When z_t changes, new state drawn from Dirichlet(1,...,1) excluding previous\n",
    "    - Feedback: r_t ~ Bernoulli(Œ∑) if correct, Bernoulli(1-Œ∑) if incorrect\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trial_num : int\n",
    "        Number of interaction steps.\n",
    "    tau_min, tau_max : float\n",
    "        Lower/upper bounds for volatility œÑ. Paper uses [0, 0.5].\n",
    "    nu : float\n",
    "        Variance of the Gaussian random walk on œÑ. Constant within block.\n",
    "    beta : float\n",
    "        Feedback reliability Œ∑. Paper: Œ∑ > 0.5, prior is Œ∑/2 ~ Beta(1,1).\n",
    "    seed : int, optional\n",
    "        RNG seed for reproducibility.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    stimuli = np.zeros(trial_num, dtype=int)  # one stimulus, two actions\n",
    "\n",
    "    tau = np.zeros(trial_num)\n",
    "    tau[0] = tau_min\n",
    "    for t in range(1, trial_num):\n",
    "        tau[t] = np.clip(rng.normal(tau[t - 1], np.sqrt(nu)), tau_min, tau_max)\n",
    "\n",
    "    latent = np.zeros(trial_num, dtype=int)\n",
    "    latent[0] = rng.integers(2)\n",
    "    traps = rng.random(trial_num) > beta  # True = reward flips\n",
    "\n",
    "    for t in range(1, trial_num):\n",
    "        if rng.random() < tau[t]:\n",
    "            latent[t] = 1 - latent[t - 1]  # with K=2, switching means flipping\n",
    "        else:\n",
    "            latent[t] = latent[t - 1]\n",
    "\n",
    "    correct_actions = latent.copy()  # mapping is identity in the closed 2-armed case\n",
    "\n",
    "    return VolatileBanditTask(\n",
    "        stimuli=stimuli,\n",
    "        latent_states=latent,\n",
    "        switch_prob=tau,\n",
    "        traps=traps,\n",
    "        correct_actions=correct_actions,\n",
    "        beta=beta,\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_stable_volatility_task(\n",
    "    trial_num: int = 200,\n",
    "    tau: float = 0.05,           # Fixed 5% volatility (stable)\n",
    "    beta: float = 0.9,           # Feedback reliability Œ∑\n",
    "    seed: Optional[int] = None,\n",
    ") -> VolatileBanditTask:\n",
    "    \"\"\"\n",
    "    üé∞ 2-ARMED BANDIT with STABLE (fixed) volatility.\n",
    "    \n",
    "    Unlike generate_bandit_task where œÑ varies via random walk, here:\n",
    "    - Volatility œÑ is CONSTANT (fixed probability of switch each trial)\n",
    "    - Feedback noise Œ∑ (beta) varies between conditions:\n",
    "      * Low noise:  Œ∑ = 0.9 (90% reliable feedback)\n",
    "      * High noise: Œ∑ = 0.7 (70% reliable feedback)\n",
    "    \n",
    "    This setup isolates the effect of NOISE while keeping volatility stable.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trial_num : int\n",
    "        Number of trials.\n",
    "    tau : float\n",
    "        Fixed switch probability. Default 0.05 (5%).\n",
    "    beta : float\n",
    "        Feedback reliability Œ∑. \n",
    "        - Low noise condition: Œ≤ = 0.9\n",
    "        - High noise condition: Œ≤ = 0.7\n",
    "    seed : int, optional\n",
    "        RNG seed for reproducibility.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    stimuli = np.zeros(trial_num, dtype=int)  # single stimulus\n",
    "    \n",
    "    # Constant volatility (no random walk!)\n",
    "    tau_array = np.full(trial_num, tau)\n",
    "    \n",
    "    # Generate latent states with fixed switch probability\n",
    "    latent = np.zeros(trial_num, dtype=int)\n",
    "    latent[0] = rng.integers(2)\n",
    "    \n",
    "    for t in range(1, trial_num):\n",
    "        if rng.random() < tau:\n",
    "            latent[t] = 1 - latent[t - 1]  # switch\n",
    "        else:\n",
    "            latent[t] = latent[t - 1]      # stay\n",
    "    \n",
    "    # Feedback noise (traps)\n",
    "    traps = rng.random(trial_num) > beta\n",
    "    \n",
    "    correct_actions = latent.copy()\n",
    "    \n",
    "    return VolatileBanditTask(\n",
    "        stimuli=stimuli,\n",
    "        latent_states=latent,\n",
    "        switch_prob=tau_array,\n",
    "        traps=traps,\n",
    "        correct_actions=correct_actions,\n",
    "        beta=beta,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "890936bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoArmedBanditEnv:\n",
    "    \"\"\"Minimal environment that feeds the agents with stimuli and rewards.\"\"\"\n",
    "\n",
    "    def __init__(self, task: VolatileBanditTask):\n",
    "        self.task = task\n",
    "        self.index = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.index = 0\n",
    "\n",
    "    def step(self, action: int) -> Tuple[int, int, int]:\n",
    "        \"\"\"Play one trial and return (stimulus, reward, correct_action).\"\"\"\n",
    "        stimulus = self.task.stimuli[self.index]\n",
    "        correct_action = self.task.correct_actions[self.index]\n",
    "        trap = self.task.traps[self.index]\n",
    "\n",
    "        if action == correct_action:\n",
    "            reward = int(not trap)\n",
    "        else:\n",
    "            reward = int(trap)\n",
    "\n",
    "        self.index += 1\n",
    "        return stimulus, reward, correct_action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e32ff5",
   "metadata": {},
   "source": [
    "### Step 2: Particle filtering utilities - the sequential Monte Carlo (SMC) algorithm\n",
    "*Reminder: a particle = a hypothesis about a parameter, weighted by how probable it is given observations*\n",
    "\n",
    "The forward models in the repo maintain two layers of particles:\n",
    "\n",
    "1. **State particles** encode beliefs over latent task-sets `z_t` and, for the varying-volatility agent, the latent hazard `œÑ_t`.\n",
    "2. **Parameter particles** encode beliefs over the hyper-parameters `(Œ≤, ŒΩ, Œ≥)` (varying volatility) or `(Œ≤, Œ≥)` (Weber).\n",
    "\n",
    "We reproduce the exact helper routines (stratified resampling, inverse-gamma sampling, etc.) here to keep the notebook self-contained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "415710e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GLOBAL CONSTANTS (required by agent classes)\n",
    "# ============================================================\n",
    "K = 2  # Number of task-sets (latent states) in closed 2-armed bandit\n",
    "\n",
    "# TASK_MAPPING[stimulus] returns array of correct actions for each task-set\n",
    "# For closed environment: stimulus 0, task-set 0 -> action 0, task-set 1 -> action 1\n",
    "TASK_MAPPING = np.array([[0, 1]])  # Shape: (n_stimuli, K) = (1, 2)\n",
    "\n",
    "def stratified_resample(weights: np.ndarray, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Stratified resampling as used in the original C++ code.\"\"\"\n",
    "    n = len(weights)\n",
    "    cumulative = np.cumsum(weights)\n",
    "    positions = (rng.random(n) + np.arange(n)) / n\n",
    "    return np.searchsorted(cumulative, positions)\n",
    "\n",
    "\n",
    "def sample_inv_gamma(shape: float, scale: float, size: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Inverse-gamma sampler matching utils/useful_functions.py.\"\"\"\n",
    "    return scale / rng.gamma(shape, size=size)\n",
    "\n",
    "\n",
    "def logsumexp(log_w: np.ndarray) -> float:\n",
    "    b = np.max(log_w)\n",
    "    return b + np.log(np.sum(np.exp(log_w - b)))\n",
    "\n",
    "\n",
    "def normalise_log_weights(log_w: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Convert log-weights to normalized weights without numerical trouble.\"\"\"\n",
    "    log_w = log_w - logsumexp(log_w)\n",
    "    return np.exp(log_w)\n",
    "\n",
    "\n",
    "def compute_positive_states(mapping: np.ndarray, stimulus: int, action: int, reward: int) -> np.ndarray:\n",
    "    \"\"\"Replicates isEqual_and_adapted_logical_xor from the C++ helpers.\"\"\"\n",
    "    equals = mapping[stimulus] == action\n",
    "    if reward:  # reward==1 means the action was *reported* as correct\n",
    "        return equals.astype(float)\n",
    "    return (~equals).astype(float)\n",
    "\n",
    "\n",
    "def sample_new_state_excluding(current: int, gamma: np.ndarray, rng: np.random.Generator) -> int:\n",
    "    probs = gamma.copy()\n",
    "    probs[current] = 0.0\n",
    "    total = probs.sum()\n",
    "    if total == 0:\n",
    "        probs[:] = 1.0 / len(probs)\n",
    "    else:\n",
    "        probs /= total\n",
    "    return rng.choice(len(probs), p=probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc3d568",
   "metadata": {},
   "source": [
    "### Step 3a: Forward varying-volatility agent\n",
    "This class mirrors `simulation_functions/varvol_forward/SMC2.py` and `lib_c/varvol_forward/SMCfunctions.cpp`:\n",
    "- Each *theta* particle samples `(Œ≤, ŒΩ, Œ≥)`.\n",
    "- Each theta carries `number_of_state_particles` state trajectories that track both latent task-set `z` and latent hazard `œÑ`.\n",
    "- After every observation we:\n",
    "  1. **Update weights** using the Bernoulli feedback likelihood.\n",
    "  2. **Resample** state trajectories within each theta according to those weights.\n",
    "  3. **Propagate** the trajectories by sampling a new `œÑ` and, with probability `œÑ`, switching to a different task-set drawn from `Œ≥`.\n",
    "  4. **Adapt** the parameter particles if the effective sample size (ESS) collapses.\n",
    "\n",
    "The result is a biologically plausible online approximation of the exact SMC¬≤ solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "249d6402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardVaryingVolatilityAgent:\n",
    "    \"\"\"Forward (online) SMC approximation of the exact varying-volatility model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_theta: int = 400, \n",
    "        num_state_particles: int = 200,\n",
    "        tau_default: float = 0.03,\n",
    "        tau_bounds: Tuple[float, float] = (0.0, 0.5),\n",
    "        beta_prior: Tuple[float, float] = (1.0, 1.0),\n",
    "        nu_prior: Tuple[float, float] = (3.0, 1e-3),\n",
    "        gamma_prior: float = 1.0,\n",
    "        ess_threshold: float = 0.5,\n",
    "        beta_softmax: Optional[float] = None,\n",
    "        epsilon_softmax: float = 0.0,\n",
    "        seed: Optional[int] = None,\n",
    "    ):\n",
    "        self.num_theta = num_theta\n",
    "        self.num_state_particles = num_state_particles\n",
    "        self.tau_default = tau_default\n",
    "        self.tau_bounds = tau_bounds\n",
    "        self.beta_prior = beta_prior\n",
    "        self.nu_prior = nu_prior\n",
    "        self.gamma_prior = gamma_prior\n",
    "        self.ess_threshold = ess_threshold\n",
    "        self.beta_softmax = beta_softmax\n",
    "        self.epsilon_softmax = epsilon_softmax\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "        self._init_particles()\n",
    "\n",
    "    def _init_particles(self):\n",
    "        self.beta_samples = self.rng.beta(\n",
    "            self.beta_prior[0], self.beta_prior[1], size=self.num_theta\n",
    "        )\n",
    "        self.nu_samples = sample_inv_gamma(\n",
    "            self.nu_prior[0], self.nu_prior[1], size=self.num_theta, rng=self.rng\n",
    "        )\n",
    "        self.gamma_samples = self.rng.dirichlet(\n",
    "            np.ones(K) * self.gamma_prior, size=self.num_theta\n",
    "        )\n",
    "        self.state_particles = self.rng.integers(\n",
    "            K, size=(self.num_theta, self.num_state_particles)\n",
    "        )\n",
    "        self.tau_particles = np.full(\n",
    "            (self.num_theta, self.num_state_particles), self.tau_default\n",
    "        )\n",
    "        self.log_theta_weights = np.zeros(self.num_theta)\n",
    "        self.theta_weights = np.ones(self.num_theta) / self.num_theta\n",
    "        self.pending_observation = None\n",
    "        self.current_action = None\n",
    "        self.current_stimulus = None\n",
    "        self.trial_index = 0\n",
    "\n",
    "        self.history = {\n",
    "            \"vol_mean\": [],\n",
    "            \"beta_mean\": [],\n",
    "            \"nu_mean\": [],\n",
    "            \"ts_prob\": [],\n",
    "        }\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Agent interaction API\n",
    "    # ------------------------------------------------------------------\n",
    "    def act(self, stimulus: int) -> Tuple[int, np.ndarray]:\n",
    "        self._maybe_smc_update()\n",
    "        action_probs = self._action_distribution(stimulus)\n",
    "        action = self._sample_action(action_probs)\n",
    "        self.current_action = action\n",
    "        self.current_stimulus = stimulus\n",
    "        return action, action_probs\n",
    "\n",
    "    def observe(self, reward: int):\n",
    "        self.pending_observation = (\n",
    "            self.current_stimulus,\n",
    "            self.current_action,\n",
    "            reward,\n",
    "        )\n",
    "        self.trial_index += 1\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # SMC internals\n",
    "    # ------------------------------------------------------------------\n",
    "    def _maybe_smc_update(self):\n",
    "        if self.pending_observation is None:\n",
    "            return\n",
    "\n",
    "        stimulus, action, reward = self.pending_observation\n",
    "        prev_states = self.state_particles.copy()\n",
    "        prev_taus = self.tau_particles.copy()\n",
    "\n",
    "        positive_states = compute_positive_states(TASK_MAPPING, stimulus, action, reward)\n",
    "        # Transform beta from [0,1] to [0.5,1] as in original code: betaSamples/2 + 0.5\n",
    "        # This ensures feedback noise Œ∑ > 0.5 (reward is more likely when action is correct)\n",
    "        beta_transformed = self.beta_samples / 2.0 + 0.5\n",
    "        beta_matrix = beta_transformed[:, None]\n",
    "        state_pos = positive_states[prev_states]\n",
    "        likelihoods = state_pos * beta_matrix + (1 - state_pos) * (1 - beta_matrix)\n",
    "        likelihoods = np.clip(likelihoods, 1e-9, None)\n",
    "\n",
    "        sum_weights = likelihoods.sum(axis=1)\n",
    "        self.log_theta_weights += np.log(sum_weights / self.num_state_particles)\n",
    "        weights_norm = likelihoods / sum_weights[:, None]\n",
    "\n",
    "        new_states = np.empty_like(prev_states)\n",
    "        new_taus = np.empty_like(prev_taus)\n",
    "        for theta_idx in range(self.num_theta):\n",
    "            ancestor_idx = stratified_resample(weights_norm[theta_idx], self.rng)\n",
    "            new_states[theta_idx] = prev_states[theta_idx, ancestor_idx]\n",
    "            new_taus[theta_idx] = prev_taus[theta_idx, ancestor_idx]\n",
    "\n",
    "        noise = self.rng.normal(\n",
    "            0.0,\n",
    "            np.sqrt(self.nu_samples)[:, None],\n",
    "            size=new_taus.shape,\n",
    "        )\n",
    "        tau_candidates = np.clip(\n",
    "            new_taus + noise, self.tau_bounds[0], self.tau_bounds[1]\n",
    "        )\n",
    "        self.tau_particles = tau_candidates\n",
    "\n",
    "        switch_mask = self.rng.random(size=new_states.shape) < tau_candidates\n",
    "        propagated_states = new_states.copy()\n",
    "        for theta_idx in range(self.num_theta):\n",
    "            gamma = self.gamma_samples[theta_idx]\n",
    "            indices = np.where(switch_mask[theta_idx])[0]\n",
    "            for idx in indices:\n",
    "                propagated_states[theta_idx, idx] = sample_new_state_excluding(\n",
    "                    propagated_states[theta_idx, idx], gamma, self.rng\n",
    "                )\n",
    "        self.state_particles = propagated_states\n",
    "\n",
    "        self.pending_observation = None\n",
    "        self.theta_weights = normalise_log_weights(self.log_theta_weights)\n",
    "        self._maybe_rejuvenate()\n",
    "        self._record_history()\n",
    "\n",
    "    def _maybe_rejuvenate(self):\n",
    "        ess = 1.0 / np.sum(self.theta_weights ** 2)\n",
    "        if ess >= self.ess_threshold * self.num_theta:\n",
    "            return\n",
    "\n",
    "        beta_mu = np.sum(self.theta_weights * self.beta_samples)\n",
    "        beta_var = np.sum(self.theta_weights * (self.beta_samples - beta_mu) ** 2)\n",
    "        beta_var = max(beta_var, 1e-6)\n",
    "        beta_alpha = max(((1 - beta_mu) / beta_var - 1 / beta_mu) * beta_mu ** 2, 1.0)\n",
    "        beta_beta = max(beta_alpha * (1 / beta_mu - 1), 1.0)\n",
    "\n",
    "        nu_mu = np.sum(self.theta_weights * self.nu_samples)\n",
    "        nu_var = np.sum(self.theta_weights * (self.nu_samples - nu_mu) ** 2)\n",
    "        nu_var = max(nu_var, 1e-6)\n",
    "        nu_alpha = nu_mu ** 2 / nu_var + 2.0\n",
    "        nu_beta = nu_mu * (nu_alpha - 1)\n",
    "\n",
    "        dirichlet_means = np.sum(\n",
    "            self.theta_weights[:, None] * self.gamma_samples, axis=0\n",
    "        )\n",
    "        dirichlet_vars = np.sum(\n",
    "            self.theta_weights[:, None] * (self.gamma_samples ** 2), axis=0\n",
    "        ) - dirichlet_means ** 2\n",
    "        dirichlet_vars = np.clip(dirichlet_vars, 1e-6, None)\n",
    "        dirichlet_precision = (\n",
    "            np.sum(dirichlet_means - dirichlet_means ** 2) / np.sum(dirichlet_vars)\n",
    "        ) - 1\n",
    "        dirichlet_precision = max(dirichlet_precision, 1.0)\n",
    "        dirichlet_params = np.maximum(\n",
    "            dirichlet_means * dirichlet_precision, 1.0\n",
    "        )\n",
    "\n",
    "        self.beta_samples = self.rng.beta(\n",
    "            beta_alpha, beta_beta, size=self.num_theta\n",
    "        )\n",
    "        self.nu_samples = sample_inv_gamma(\n",
    "            nu_alpha, nu_beta, size=self.num_theta, rng=self.rng\n",
    "        )\n",
    "        self.gamma_samples = self.rng.dirichlet(\n",
    "            dirichlet_params, size=self.num_theta\n",
    "        )\n",
    "        self.log_theta_weights[:] = 0.0\n",
    "        self.theta_weights = np.ones(self.num_theta) / self.num_theta\n",
    "\n",
    "    def _record_history(self):\n",
    "        tau_means = self.tau_particles.mean(axis=1)\n",
    "        vol_mean = np.sum(self.theta_weights * tau_means)\n",
    "        beta_mean = np.sum(self.theta_weights * self.beta_samples)\n",
    "        nu_mean = np.sum(self.theta_weights * self.nu_samples)\n",
    "        ts_prob = self._taskset_probability(self.theta_weights)\n",
    "\n",
    "        self.history[\"vol_mean\"].append(vol_mean)\n",
    "        self.history[\"beta_mean\"].append(beta_mean)\n",
    "        self.history[\"nu_mean\"].append(nu_mean)\n",
    "        self.history[\"ts_prob\"].append(ts_prob)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Decision policy helpers\n",
    "    # ------------------------------------------------------------------\n",
    "    def _taskset_probability(self, theta_weights: np.ndarray) -> np.ndarray:\n",
    "        ts_prob = np.zeros(K)\n",
    "        for theta_idx in range(self.num_theta):\n",
    "            counts = np.bincount(\n",
    "                self.state_particles[theta_idx], minlength=K\n",
    "            ) / self.num_state_particles\n",
    "            ts_prob += theta_weights[theta_idx] * counts\n",
    "        ts_prob /= np.sum(ts_prob)\n",
    "        return ts_prob\n",
    "\n",
    "    def _action_distribution(self, stimulus: int) -> np.ndarray:\n",
    "        ts_prob = self._taskset_probability(self.theta_weights)\n",
    "        action_probs = np.zeros(2)\n",
    "        for action in range(2):\n",
    "            mask = TASK_MAPPING[stimulus] == action\n",
    "            action_probs[action] = ts_prob[mask].sum()\n",
    "        if self.beta_softmax is None:\n",
    "            greedy_action = np.argmax(action_probs)\n",
    "            probs = np.zeros_like(action_probs)\n",
    "            probs[greedy_action] = 1.0\n",
    "            return probs\n",
    "        logits = action_probs * self.beta_softmax\n",
    "        logits -= np.max(logits)\n",
    "        probs = np.exp(logits)\n",
    "        probs /= probs.sum()\n",
    "        probs = probs * (1 - self.epsilon_softmax) + self.epsilon_softmax / len(probs)\n",
    "        return probs\n",
    "\n",
    "    def _sample_action(self, action_probs: np.ndarray) -> int:\n",
    "        if np.isclose(action_probs.sum(), 0):\n",
    "            return self.rng.integers(2)\n",
    "        if np.count_nonzero(action_probs) == 1:\n",
    "            return int(np.argmax(action_probs))\n",
    "        return self.rng.choice(len(action_probs), p=action_probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad88ae",
   "metadata": {},
   "source": [
    "### Step 3b: Weber-imprecision agent\n",
    "The zero-volatility model assumes that the hazard `œÑ` is fixed (no environmental switches). The Weber-imprecision variant injects noise directly into the particle filter:\n",
    "- Each theta particle still tracks `(Œ≤, Œ≥)`.\n",
    "- After observing a reward we compute the *distance* `d_t` between the pre-update (`ante`) and post-update (`post`) task-set beliefs (L1 distance, as in the C++ backend).\n",
    "- The particle mis-encodes the next state with probability `Œµ_t ~ U(0, Œº + Œª d_t)`. When a mis-encoding happens the state particle is redrawn from `Œ≥`.\n",
    "\n",
    "Setting `Œº = 0` and `Œª = 0` collapses the model back to the deterministic zero-volatility case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "608743de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeberImprecisionAgent:\n",
    "    \"\"\"Forward Weber-imprecision agent (aka precision model).\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_theta: int = 400,\n",
    "        num_state_particles: int = 200,\n",
    "        lambdaa: float = 0.9,\n",
    "        mu: float = 0.05,\n",
    "        beta_prior: Tuple[float, float] = (1.0, 1.0),\n",
    "        gamma_prior: float = 1.0,\n",
    "        ess_threshold: float = 0.5,\n",
    "        beta_softmax: Optional[float] = None,\n",
    "        epsilon_softmax: float = 0.0,\n",
    "        seed: Optional[int] = None,\n",
    "    ):\n",
    "        self.num_theta = num_theta\n",
    "        self.num_state_particles = num_state_particles\n",
    "        self.lambdaa = lambdaa\n",
    "        self.mu = mu\n",
    "        self.beta_prior = beta_prior\n",
    "        self.gamma_prior = gamma_prior\n",
    "        self.ess_threshold = ess_threshold\n",
    "        self.beta_softmax = beta_softmax\n",
    "        self.epsilon_softmax = epsilon_softmax\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "        self._init_particles()\n",
    "\n",
    "    def _init_particles(self):\n",
    "        self.beta_samples = self.rng.beta(\n",
    "            self.beta_prior[0], self.beta_prior[1], size=self.num_theta\n",
    "        )\n",
    "        self.gamma_samples = self.rng.dirichlet(\n",
    "            np.ones(K) * self.gamma_prior, size=self.num_theta\n",
    "        )\n",
    "        self.state_particles = self.rng.integers(\n",
    "            K, size=(self.num_theta, self.num_state_particles)\n",
    "        )\n",
    "        self.log_theta_weights = np.zeros(self.num_theta)\n",
    "        self.theta_weights = np.ones(self.num_theta) / self.num_theta\n",
    "        self.pending_observation = None\n",
    "        self.current_action = None\n",
    "        self.current_stimulus = None\n",
    "\n",
    "        self.history = {\n",
    "            \"epsilon\": [],\n",
    "            \"beta_mean\": [],\n",
    "            \"ts_prob\": [],\n",
    "        }\n",
    "\n",
    "    def act(self, stimulus: int) -> Tuple[int, np.ndarray]:\n",
    "        self._maybe_smc_update()\n",
    "        action_probs = self._action_distribution(stimulus)\n",
    "        action = self._sample_action(action_probs)\n",
    "        self.current_action = action\n",
    "        self.current_stimulus = stimulus\n",
    "        return action, action_probs\n",
    "\n",
    "    def observe(self, reward: int):\n",
    "        self.pending_observation = (\n",
    "            self.current_stimulus,\n",
    "            self.current_action,\n",
    "            reward,\n",
    "        )\n",
    "\n",
    "    def _maybe_smc_update(self):\n",
    "        if self.pending_observation is None:\n",
    "            return\n",
    "\n",
    "        stimulus, action, reward = self.pending_observation\n",
    "        prev_states = self.state_particles.copy()\n",
    "\n",
    "        positive_states = compute_positive_states(TASK_MAPPING, stimulus, action, reward)\n",
    "        # Transform beta from [0,1] to [0.5,1] as in original code: betaSamples/2 + 0.5\n",
    "        # This ensures feedback noise Œ∑ > 0.5 (reward is more likely when action is correct)\n",
    "        beta_transformed = self.beta_samples / 2.0 + 0.5\n",
    "        beta_matrix = beta_transformed[:, None]\n",
    "        state_pos = positive_states[prev_states]\n",
    "        likelihoods = state_pos * beta_matrix + (1 - state_pos) * (1 - beta_matrix)\n",
    "        likelihoods = np.clip(likelihoods, 1e-9, None)\n",
    "\n",
    "        ante_counts = (\n",
    "            np.apply_along_axis(\n",
    "                lambda row: np.bincount(row, minlength=K), 1, prev_states\n",
    "            )\n",
    "            / self.num_state_particles\n",
    "        )\n",
    "        weighted_post = np.zeros_like(ante_counts)\n",
    "        sum_weights = likelihoods.sum(axis=1)\n",
    "        weights_norm = likelihoods / sum_weights[:, None]\n",
    "        for theta_idx in range(self.num_theta):\n",
    "            for state_idx in range(self.num_state_particles):\n",
    "                s = prev_states[theta_idx, state_idx]\n",
    "                weighted_post[theta_idx, s] += weights_norm[theta_idx, state_idx]\n",
    "\n",
    "        weighted_post = np.divide(\n",
    "            weighted_post,\n",
    "            weighted_post.sum(axis=1, keepdims=True) + 1e-12,\n",
    "        )\n",
    "\n",
    "        distances = np.sum(np.abs(ante_counts - weighted_post), axis=1)\n",
    "        epsilons = np.clip(self.mu + self.lambdaa * distances, 0.0, 1.0) / 2.0\n",
    "        self.history[\"epsilon\"].append(epsilons.mean())\n",
    "\n",
    "        self.log_theta_weights += np.log(sum_weights / self.num_state_particles)\n",
    "\n",
    "        new_states = np.empty_like(prev_states)\n",
    "        for theta_idx in range(self.num_theta):\n",
    "            ancestor_idx = stratified_resample(weights_norm[theta_idx], self.rng)\n",
    "            candidates = prev_states[theta_idx, ancestor_idx]\n",
    "            keep_mask = self.rng.random(self.num_state_particles) > epsilons[theta_idx]\n",
    "            for s_idx in range(self.num_state_particles):\n",
    "                if keep_mask[s_idx]:\n",
    "                    new_states[theta_idx, s_idx] = candidates[s_idx]\n",
    "                else:\n",
    "                    new_states[theta_idx, s_idx] = self.rng.choice(\n",
    "                        K, p=self.gamma_samples[theta_idx]\n",
    "                    )\n",
    "        self.state_particles = new_states\n",
    "\n",
    "        self.pending_observation = None\n",
    "        self.theta_weights = normalise_log_weights(self.log_theta_weights)\n",
    "        self._maybe_rejuvenate()\n",
    "        self._record_history()\n",
    "\n",
    "    def _maybe_rejuvenate(self):\n",
    "        ess = 1.0 / np.sum(self.theta_weights ** 2)\n",
    "        if ess >= self.ess_threshold * self.num_theta:\n",
    "            return\n",
    "\n",
    "        beta_mu = np.sum(self.theta_weights * self.beta_samples)\n",
    "        beta_var = np.sum(self.theta_weights * (self.beta_samples - beta_mu) ** 2)\n",
    "        beta_var = max(beta_var, 1e-6)\n",
    "        beta_alpha = max(((1 - beta_mu) / beta_var - 1 / beta_mu) * beta_mu ** 2, 1.0)\n",
    "        beta_beta = max(beta_alpha * (1 / beta_mu - 1), 1.0)\n",
    "\n",
    "        dirichlet_means = np.sum(\n",
    "            self.theta_weights[:, None] * self.gamma_samples, axis=0\n",
    "        )\n",
    "        dirichlet_vars = np.sum(\n",
    "            self.theta_weights[:, None] * (self.gamma_samples ** 2), axis=0\n",
    "        ) - dirichlet_means ** 2\n",
    "        dirichlet_vars = np.clip(dirichlet_vars, 1e-6, None)\n",
    "        dirichlet_precision = (\n",
    "            np.sum(dirichlet_means - dirichlet_means ** 2) / np.sum(dirichlet_vars)\n",
    "        ) - 1\n",
    "        dirichlet_precision = max(dirichlet_precision, 1.0)\n",
    "        dirichlet_params = np.maximum(\n",
    "            dirichlet_means * dirichlet_precision, 1.0\n",
    "        )\n",
    "\n",
    "        self.beta_samples = self.rng.beta(\n",
    "            beta_alpha, beta_beta, size=self.num_theta\n",
    "        )\n",
    "        self.gamma_samples = self.rng.dirichlet(\n",
    "            dirichlet_params, size=self.num_theta\n",
    "        )\n",
    "        self.log_theta_weights[:] = 0.0\n",
    "        self.theta_weights = np.ones(self.num_theta) / self.num_theta\n",
    "\n",
    "    def _record_history(self):\n",
    "        beta_mean = np.sum(self.theta_weights * self.beta_samples)\n",
    "        ts_prob = self._taskset_probability()\n",
    "        self.history[\"beta_mean\"].append(beta_mean)\n",
    "        self.history[\"ts_prob\"].append(ts_prob)\n",
    "\n",
    "    def _taskset_probability(self) -> np.ndarray:\n",
    "        ts_prob = np.zeros(K)\n",
    "        for theta_idx in range(self.num_theta):\n",
    "            counts = np.bincount(\n",
    "                self.state_particles[theta_idx], minlength=K\n",
    "            ) / self.num_state_particles\n",
    "            ts_prob += self.theta_weights[theta_idx] * counts\n",
    "        ts_prob /= np.sum(ts_prob)\n",
    "        return ts_prob\n",
    "\n",
    "    def _action_distribution(self, stimulus: int) -> np.ndarray:\n",
    "        ts_prob = self._taskset_probability()\n",
    "        action_probs = np.zeros(2)\n",
    "        for action in range(2):\n",
    "            mask = TASK_MAPPING[stimulus] == action\n",
    "            action_probs[action] = ts_prob[mask].sum()\n",
    "        if self.beta_softmax is None:\n",
    "            greedy_action = np.argmax(action_probs)\n",
    "            probs = np.zeros_like(action_probs)\n",
    "            probs[greedy_action] = 1.0\n",
    "            return probs\n",
    "        logits = action_probs * self.beta_softmax\n",
    "        logits -= np.max(logits)\n",
    "        probs = np.exp(logits)\n",
    "        probs /= probs.sum()\n",
    "        probs = probs * (1 - self.epsilon_softmax) + self.epsilon_softmax / len(probs)\n",
    "        return probs\n",
    "\n",
    "    def _sample_action(self, action_probs: np.ndarray) -> int:\n",
    "        if np.isclose(action_probs.sum(), 0):\n",
    "            return self.rng.integers(2)\n",
    "        if np.count_nonzero(action_probs) == 1:\n",
    "            return int(np.argmax(action_probs))\n",
    "        return self.rng.choice(len(action_probs), p=action_probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba6651ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîß MLE PARAMETER FITTING: Fitting Models to Human Data\n",
      "======================================================================\n",
      "\n",
      "‚ö†Ô∏è  TESTING MODE: Using minimal particles for speed\n",
      "   num_theta: 50, num_state: 50\n",
      "   max_iter: 50\n",
      "   For production, increase to 200/200/200\n",
      "\n",
      "Found 2 participant files in participant_data\\extended_csvs\n",
      "\n",
      "Fitting models to 2 participants...\n",
      "This may take a few minutes with minimal particles.\n",
      "\n",
      "  Processed 2/2 participants (450.5s)\n",
      "\n",
      "‚úì Fitting complete in 450.5 seconds\n",
      "\n",
      "======================================================================\n",
      "üìä MLE FITTING RESULTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Participants fitted: 2\n",
      "VarVol wins (lower BIC): 2 (100.0%)\n",
      "Weber wins (lower BIC):  0 (0.0%)\n",
      "\n",
      "Metric                    VarVol          Weber          \n",
      "-------------------------------------------------------\n",
      "Mean Log-Likelihood       -67.58          -64.90         \n",
      "Mean BIC                  139.76          143.61         \n",
      "Sum BIC                   279.51          287.22         \n",
      "\n",
      "Mean ŒîBIC (VV-Weber)      -3.85          \n",
      "Sum ŒîBIC (VV-Weber)       -7.71          \n",
      "\n",
      "‚Üí Overall: VarVol is favored (sum ŒîBIC = -7.7)\n",
      "\n",
      "======================================================================\n",
      "üìà FITTED PARAMETER DISTRIBUTIONS (Findling et al. 2021)\n",
      "======================================================================\n",
      "\n",
      "VarVol fitted parameters (1 free param):\n",
      "  Œ≤ (beta_softmax): mean=1.04, std=0.14, range=[0.94, 1.14]\n",
      "\n",
      "Weber fitted parameters (3 free params):\n",
      "  Œ≤ (beta_softmax): mean=1.78, std=0.53, range=[1.41, 2.16]\n",
      "  Œª (lambdaa):      mean=0.40, std=0.00, range=[0.40, 0.40]\n",
      "  Œº (mu):           mean=0.100, std=0.000, range=[0.100, 0.100]\n",
      "\n",
      "üíæ Saved fitting results to: participant_data\\mle_fitting_results.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Figure saved to: participant_data/mle_fitting_results.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üîß MLE PARAMETER FITTING: Fit Models to Human Data\n",
    "# ============================================================\n",
    "# This section fits model parameters to human choice data using\n",
    "# Maximum Likelihood Estimation (MLE), as done in Findling et al. (2021).\n",
    "#\n",
    "# For each participant √ó model:\n",
    "#   1. Reconstruct the task they experienced\n",
    "#   2. Find params that maximize P(human_choices | model, params)\n",
    "#   3. Store fitted params and log-likelihood for BIC comparison\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîß MLE PARAMETER FITTING: Fitting Models to Human Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================\n",
    "# Settings for fitting (MINIMAL for testing)\n",
    "# ============================================================\n",
    "FITTING_N_THETA = 50        # Reduced particles for speed (was 200)\n",
    "FITTING_N_STATE = 50        # Reduced particles for speed (was 200)\n",
    "MAX_OPTIM_ITER = 50         # Limit optimization iterations\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  TESTING MODE: Using minimal particles for speed\")\n",
    "print(f\"   num_theta: {FITTING_N_THETA}, num_state: {FITTING_N_STATE}\")\n",
    "print(f\"   max_iter: {MAX_OPTIM_ITER}\")\n",
    "print(f\"   For production, increase to 200/200/200\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# Reconstruct task from human data\n",
    "# ============================================================\n",
    "def reconstruct_task_from_human_data(participant_df: pd.DataFrame) -> VolatileBanditTask:\n",
    "    \"\"\"\n",
    "    Reconstruct a VolatileBanditTask from human behavioral data.\n",
    "    Uses: hidden_state (correct arm) and false_feedback (trap trials)\n",
    "    \"\"\"\n",
    "    n_trials = len(participant_df)\n",
    "    \n",
    "    # Extract true states and traps\n",
    "    correct_actions = participant_df['hidden_state'].values.astype(int)\n",
    "    traps = participant_df['false_feedback'].values.astype(bool)\n",
    "    \n",
    "    # Infer volatility (œÑ) from switch rate\n",
    "    switches = np.sum(np.diff(correct_actions) != 0)\n",
    "    switch_rate = switches / (n_trials - 1) if n_trials > 1 else 0.0\n",
    "    switch_prob = np.full(n_trials, switch_rate)\n",
    "    \n",
    "    # Infer feedback reliability (Œ≤) from trap rate\n",
    "    trap_rate = np.mean(traps)\n",
    "    beta = 1.0 - trap_rate\n",
    "    \n",
    "    # Create task\n",
    "    stimuli = np.zeros(n_trials, dtype=int)\n",
    "    latent_states = correct_actions.copy()\n",
    "    \n",
    "    return VolatileBanditTask(\n",
    "        stimuli=stimuli,\n",
    "        latent_states=latent_states,\n",
    "        switch_prob=switch_prob,\n",
    "        traps=traps,\n",
    "        correct_actions=correct_actions,\n",
    "        beta=beta,\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# Negative Log-Likelihood function (to minimize)\n",
    "# ============================================================\n",
    "# Following Findling et al. (2021):\n",
    "#   - VarVol: 1 free parameter (Œ≤ = inverse temperature)\n",
    "#   - Weber:  3 free parameters (Œ≤, Œº, Œª)\n",
    "\n",
    "def compute_neg_log_likelihood_varvol(params, task, human_choices):\n",
    "    \"\"\"\n",
    "    Compute negative log-likelihood for VarVol model.\n",
    "    params: [beta_softmax]  # Only 1 parameter per Findling et al.\n",
    "    \"\"\"\n",
    "    beta_softmax = params[0]\n",
    "    \n",
    "    # Clamp to valid range\n",
    "    beta_softmax = max(0.01, beta_softmax)\n",
    "    \n",
    "    try:\n",
    "        agent = ForwardVaryingVolatilityAgent(\n",
    "            num_theta=FITTING_N_THETA,\n",
    "            num_state_particles=FITTING_N_STATE,\n",
    "            beta_softmax=beta_softmax,\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        env = TwoArmedBanditEnv(task)\n",
    "        env.reset()\n",
    "        \n",
    "        log_lik = 0.0\n",
    "        for t in range(len(human_choices)):\n",
    "            stimulus = task.stimuli[t]\n",
    "            _, action_probs = agent.act(stimulus)\n",
    "            \n",
    "            # Likelihood of HUMAN's choice (not correct action!)\n",
    "            human_choice = human_choices[t]\n",
    "            prob_human_choice = action_probs[human_choice]\n",
    "            prob_human_choice = np.clip(prob_human_choice, 1e-10, 1.0)\n",
    "            log_lik += np.log(prob_human_choice)\n",
    "            \n",
    "            # Observe actual reward (what human got)\n",
    "            _, reward, _ = env.step(human_choice)\n",
    "            agent.observe(reward)\n",
    "        \n",
    "        return -log_lik  # Negative because we minimize\n",
    "    except Exception as e:\n",
    "        return 1e10  # Return large value on error\n",
    "\n",
    "\n",
    "def compute_neg_log_likelihood_weber(params, task, human_choices):\n",
    "    \"\"\"\n",
    "    Compute negative log-likelihood for Weber model.\n",
    "    params: [beta_softmax, lambdaa, mu]  # 3 parameters per Findling et al.\n",
    "    \"\"\"\n",
    "    beta_softmax, lambdaa, mu = params\n",
    "    \n",
    "    # Clamp to valid ranges\n",
    "    beta_softmax = max(0.01, beta_softmax)\n",
    "    lambdaa = np.clip(lambdaa, 0.01, 2.0)\n",
    "    mu = np.clip(mu, 0.001, 1.0)\n",
    "    \n",
    "    try:\n",
    "        agent = WeberImprecisionAgent(\n",
    "            num_theta=FITTING_N_THETA,\n",
    "            num_state_particles=FITTING_N_STATE,\n",
    "            beta_softmax=beta_softmax,\n",
    "            lambdaa=lambdaa,\n",
    "            mu=mu,\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        env = TwoArmedBanditEnv(task)\n",
    "        env.reset()\n",
    "        \n",
    "        log_lik = 0.0\n",
    "        for t in range(len(human_choices)):\n",
    "            stimulus = task.stimuli[t]\n",
    "            _, action_probs = agent.act(stimulus)\n",
    "            \n",
    "            # Likelihood of HUMAN's choice\n",
    "            human_choice = human_choices[t]\n",
    "            prob_human_choice = action_probs[human_choice]\n",
    "            prob_human_choice = np.clip(prob_human_choice, 1e-10, 1.0)\n",
    "            log_lik += np.log(prob_human_choice)\n",
    "            \n",
    "            # Observe actual reward\n",
    "            _, reward, _ = env.step(human_choice)\n",
    "            agent.observe(reward)\n",
    "        \n",
    "        return -log_lik\n",
    "    except Exception as e:\n",
    "        return 1e10\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Fit model to one participant\n",
    "# ============================================================\n",
    "# Following Findling et al. (2021):\n",
    "#   - VarVol: 1 parameter (Œ≤)\n",
    "#   - Weber:  3 parameters (Œ≤, Œº, Œª)\n",
    "\n",
    "def fit_varvol_to_participant(task, human_choices):\n",
    "    \"\"\"Fit VarVol parameters to one participant's choices.\n",
    "    \n",
    "    Findling et al. (2021): VarVol has 1 free parameter (Œ≤ only).\n",
    "    \"\"\"\n",
    "    # Initial params: [beta_softmax]\n",
    "    x0 = [1.0]  # Findling default\n",
    "    bounds = [(0.01, 10.0)]\n",
    "    \n",
    "    result = minimize(\n",
    "        compute_neg_log_likelihood_varvol,\n",
    "        x0,\n",
    "        args=(task, human_choices),\n",
    "        method='L-BFGS-B',\n",
    "        bounds=bounds,\n",
    "        options={'maxiter': MAX_OPTIM_ITER, 'disp': False}\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'beta_softmax': result.x[0],\n",
    "        'neg_log_lik': result.fun,\n",
    "        'log_lik': -result.fun,\n",
    "        'success': result.success,\n",
    "        'n_params': 1  # Findling: 1 parameter\n",
    "    }\n",
    "\n",
    "\n",
    "def fit_weber_to_participant(task, human_choices):\n",
    "    \"\"\"Fit Weber parameters to one participant's choices.\n",
    "    \n",
    "    Findling et al. (2021): Weber has 3 free parameters (Œ≤, Œº, Œª).\n",
    "    \"\"\"\n",
    "    # Initial params: [beta_softmax, lambdaa, mu]\n",
    "    x0 = [1.0, 0.4, 0.1]  # Findling defaults\n",
    "    bounds = [(0.01, 10.0), (0.01, 2.0), (0.001, 1.0)]\n",
    "    \n",
    "    result = minimize(\n",
    "        compute_neg_log_likelihood_weber,\n",
    "        x0,\n",
    "        args=(task, human_choices),\n",
    "        method='L-BFGS-B',\n",
    "        bounds=bounds,\n",
    "        options={'maxiter': MAX_OPTIM_ITER, 'disp': False}\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'beta_softmax': result.x[0],\n",
    "        'lambdaa': result.x[1],\n",
    "        'mu': result.x[2],\n",
    "        'neg_log_lik': result.fun,\n",
    "        'log_lik': -result.fun,\n",
    "        'success': result.success,\n",
    "        'n_params': 3  # Findling: 3 parameters\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Run MLE fitting on all participants\n",
    "# ============================================================\n",
    "DATA_DIR = Path('participant_data/extended_csvs')\n",
    "csv_files = sorted(DATA_DIR.glob('*.csv'))[:2]\n",
    "print(f\"Found {len(csv_files)} participant files in {DATA_DIR}\")\n",
    "\n",
    "if len(csv_files) == 0:\n",
    "    print(\"‚ùå No participant files found! Check DATA_DIR path.\")\n",
    "else:\n",
    "    # Store results\n",
    "    fitting_results = []\n",
    "    \n",
    "    print(f\"\\nFitting models to {len(csv_files)} participants...\")\n",
    "    print(\"This may take a few minutes with minimal particles.\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, csv_file in enumerate(csv_files):\n",
    "        participant_id = csv_file.stem\n",
    "        \n",
    "        # Load data\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Skip if missing required columns\n",
    "        if 'hidden_state' not in df.columns or 'false_feedback' not in df.columns:\n",
    "            print(f\"  ‚ö†Ô∏è  Skipping {participant_id}: missing columns\")\n",
    "            continue\n",
    "        \n",
    "        # Reconstruct task and get human choices\n",
    "        task = reconstruct_task_from_human_data(df)\n",
    "        human_choices = df['userChoice'].values.astype(int)\n",
    "        n_trials = len(human_choices)\n",
    "        \n",
    "        # Fit VarVol\n",
    "        varvol_fit = fit_varvol_to_participant(task, human_choices)\n",
    "        \n",
    "        # Fit Weber\n",
    "        weber_fit = fit_weber_to_participant(task, human_choices)\n",
    "        \n",
    "        # Compute BIC for each\n",
    "        # BIC = k * ln(n) - 2 * ln(L) = k * ln(n) + 2 * neg_log_lik\n",
    "        varvol_bic = varvol_fit['n_params'] * np.log(n_trials) + 2 * varvol_fit['neg_log_lik']\n",
    "        weber_bic = weber_fit['n_params'] * np.log(n_trials) + 2 * weber_fit['neg_log_lik']\n",
    "        \n",
    "        # Store\n",
    "        # Following Findling et al.: VarVol has 1 param (Œ≤), Weber has 3 params (Œ≤, Œª, Œº)\n",
    "        fitting_results.append({\n",
    "            'participant_id': participant_id,\n",
    "            'n_trials': n_trials,\n",
    "            # VarVol (1 parameter: Œ≤)\n",
    "            'varvol_beta_softmax': varvol_fit['beta_softmax'],\n",
    "            'varvol_log_lik': varvol_fit['log_lik'],\n",
    "            'varvol_bic': varvol_bic,\n",
    "            'varvol_n_params': varvol_fit['n_params'],\n",
    "            'varvol_success': varvol_fit['success'],\n",
    "            # Weber (3 parameters: Œ≤, Œª, Œº)\n",
    "            'weber_beta_softmax': weber_fit['beta_softmax'],\n",
    "            'weber_lambdaa': weber_fit['lambdaa'],\n",
    "            'weber_mu': weber_fit['mu'],\n",
    "            'weber_log_lik': weber_fit['log_lik'],\n",
    "            'weber_bic': weber_bic,\n",
    "            'weber_n_params': weber_fit['n_params'],\n",
    "            'weber_success': weber_fit['success'],\n",
    "            # Comparison\n",
    "            'delta_bic': varvol_bic - weber_bic,  # Negative = VarVol better\n",
    "            'better_model': 'VarVol' if varvol_bic < weber_bic else 'Weber'\n",
    "        })\n",
    "        \n",
    "        # Progress\n",
    "        if (i + 1) % 5 == 0 or (i + 1) == len(csv_files):\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"  Processed {i+1}/{len(csv_files)} participants ({elapsed:.1f}s)\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n‚úì Fitting complete in {total_time:.1f} seconds\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    fitting_df = pd.DataFrame(fitting_results)\n",
    "    \n",
    "    # ============================================================\n",
    "    # Summary Statistics\n",
    "    # ============================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä MLE FITTING RESULTS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    n_participants = len(fitting_df)\n",
    "    n_varvol_wins = (fitting_df['better_model'] == 'VarVol').sum()\n",
    "    n_weber_wins = (fitting_df['better_model'] == 'Weber').sum()\n",
    "    \n",
    "    print(f\"\\nParticipants fitted: {n_participants}\")\n",
    "    print(f\"VarVol wins (lower BIC): {n_varvol_wins} ({100*n_varvol_wins/n_participants:.1f}%)\")\n",
    "    print(f\"Weber wins (lower BIC):  {n_weber_wins} ({100*n_weber_wins/n_participants:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n{'Metric':<25} {'VarVol':<15} {'Weber':<15}\")\n",
    "    print(\"-\"*55)\n",
    "    print(f\"{'Mean Log-Likelihood':<25} {fitting_df['varvol_log_lik'].mean():<15.2f} {fitting_df['weber_log_lik'].mean():<15.2f}\")\n",
    "    print(f\"{'Mean BIC':<25} {fitting_df['varvol_bic'].mean():<15.2f} {fitting_df['weber_bic'].mean():<15.2f}\")\n",
    "    print(f\"{'Sum BIC':<25} {fitting_df['varvol_bic'].sum():<15.2f} {fitting_df['weber_bic'].sum():<15.2f}\")\n",
    "    \n",
    "    # ŒîBIC statistics\n",
    "    delta_bic_mean = fitting_df['delta_bic'].mean()\n",
    "    delta_bic_sum = fitting_df['delta_bic'].sum()\n",
    "    \n",
    "    print(f\"\\n{'Mean ŒîBIC (VV-Weber)':<25} {delta_bic_mean:<15.2f}\")\n",
    "    print(f\"{'Sum ŒîBIC (VV-Weber)':<25} {delta_bic_sum:<15.2f}\")\n",
    "    \n",
    "    if delta_bic_sum < 0:\n",
    "        print(f\"\\n‚Üí Overall: VarVol is favored (sum ŒîBIC = {delta_bic_sum:.1f})\")\n",
    "    else:\n",
    "        print(f\"\\n‚Üí Overall: Weber is favored (sum ŒîBIC = {delta_bic_sum:.1f})\")\n",
    "    \n",
    "    # Fitted parameter distributions\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìà FITTED PARAMETER DISTRIBUTIONS (Findling et al. 2021)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nVarVol fitted parameters (1 free param):\")\n",
    "    print(f\"  Œ≤ (beta_softmax): mean={fitting_df['varvol_beta_softmax'].mean():.2f}, \"\n",
    "          f\"std={fitting_df['varvol_beta_softmax'].std():.2f}, \"\n",
    "          f\"range=[{fitting_df['varvol_beta_softmax'].min():.2f}, {fitting_df['varvol_beta_softmax'].max():.2f}]\")\n",
    "    \n",
    "    print(f\"\\nWeber fitted parameters (3 free params):\")\n",
    "    print(f\"  Œ≤ (beta_softmax): mean={fitting_df['weber_beta_softmax'].mean():.2f}, \"\n",
    "          f\"std={fitting_df['weber_beta_softmax'].std():.2f}, \"\n",
    "          f\"range=[{fitting_df['weber_beta_softmax'].min():.2f}, {fitting_df['weber_beta_softmax'].max():.2f}]\")\n",
    "    print(f\"  Œª (lambdaa):      mean={fitting_df['weber_lambdaa'].mean():.2f}, \"\n",
    "          f\"std={fitting_df['weber_lambdaa'].std():.2f}, \"\n",
    "          f\"range=[{fitting_df['weber_lambdaa'].min():.2f}, {fitting_df['weber_lambdaa'].max():.2f}]\")\n",
    "    print(f\"  Œº (mu):           mean={fitting_df['weber_mu'].mean():.3f}, \"\n",
    "          f\"std={fitting_df['weber_mu'].std():.3f}, \"\n",
    "          f\"range=[{fitting_df['weber_mu'].min():.3f}, {fitting_df['weber_mu'].max():.3f}]\")\n",
    "    \n",
    "    # Save results\n",
    "    output_path = Path('participant_data/mle_fitting_results.csv')\n",
    "    fitting_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nüíæ Saved fitting results to: {output_path}\")\n",
    "    \n",
    "    # Quick visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Plot 1: BIC comparison per participant\n",
    "    ax = axes[0]\n",
    "    x = np.arange(len(fitting_df))\n",
    "    ax.bar(x - 0.2, fitting_df['varvol_bic'], 0.4, label='VarVol', alpha=0.7)\n",
    "    ax.bar(x + 0.2, fitting_df['weber_bic'], 0.4, label='Weber', alpha=0.7)\n",
    "    ax.set_xlabel('Participant')\n",
    "    ax.set_ylabel('BIC (lower is better)')\n",
    "    ax.set_title('BIC per Participant')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Plot 2: ŒîBIC distribution\n",
    "    ax = axes[1]\n",
    "    ax.hist(fitting_df['delta_bic'], bins=15, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Equal')\n",
    "    ax.axvline(fitting_df['delta_bic'].mean(), color='black', linestyle='-', \n",
    "               linewidth=2, label=f'Mean: {delta_bic_mean:.1f}')\n",
    "    ax.set_xlabel('ŒîBIC (VarVol - Weber)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('ŒîBIC Distribution\\n(negative = VarVol better)')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Plot 3: Model wins pie chart\n",
    "    ax = axes[2]\n",
    "    ax.pie([n_varvol_wins, n_weber_wins], \n",
    "           labels=['VarVol', 'Weber'],\n",
    "           autopct='%1.1f%%',\n",
    "           colors=['#1f77b4', '#ff7f0e'])\n",
    "    ax.set_title('Which Model Wins? (BIC)')\n",
    "    \n",
    "    plt.suptitle('MLE Parameter Fitting Results', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('participant_data/mle_fitting_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Figure saved to: participant_data/mle_fitting_results.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8269922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üìä COMPREHENSIVE VISUALIZATIONS: Model Comparison\n",
    "# ============================================================\n",
    "# Run this AFTER the MLE fitting cell completes!\n",
    "# Assumes `fitting_df` exists from the previous cell.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Check if fitting_df exists\n",
    "if 'fitting_df' not in dir():\n",
    "    print(\"‚ùå fitting_df not found! Run the MLE fitting cell first.\")\n",
    "else:\n",
    "    print(\"=\"*70)\n",
    "    print(\"üìä GENERATING VISUALIZATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Set up style\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    \n",
    "    # ============================================================\n",
    "    # FIGURE 1: BIC Model Comparison (3 panels)\n",
    "    # ============================================================\n",
    "    fig1, axes1 = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig1.suptitle('Figure 1: BIC Model Comparison', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Panel 1a: BIC per participant\n",
    "    ax = axes1[0]\n",
    "    n_participants = len(fitting_df)\n",
    "    x = np.arange(n_participants)\n",
    "    width = 0.35\n",
    "    bars1 = ax.bar(x - width/2, fitting_df['varvol_bic'], width, label='VarVol', color='#2ecc71', alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, fitting_df['weber_bic'], width, label='Weber', color='#e74c3c', alpha=0.8)\n",
    "    ax.set_xlabel('Participant')\n",
    "    ax.set_ylabel('BIC (lower = better)')\n",
    "    ax.set_title('BIC per Participant')\n",
    "    ax.legend()\n",
    "    ax.set_xticks(x[::5])  # Show every 5th tick\n",
    "    \n",
    "    # Panel 1b: ŒîBIC distribution\n",
    "    ax = axes1[1]\n",
    "    delta_bic = fitting_df['delta_bic']\n",
    "    ax.hist(delta_bic, bins=20, color='#3498db', alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Equal models')\n",
    "    ax.axvline(delta_bic.mean(), color='black', linestyle='-', linewidth=2, \n",
    "               label=f'Mean: {delta_bic.mean():.1f}')\n",
    "    ax.set_xlabel('ŒîBIC (VarVol - Weber)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('ŒîBIC Distribution')\n",
    "    ax.legend(fontsize=8)\n",
    "    \n",
    "    # Panel 1c: Model wins pie chart\n",
    "    ax = axes1[2]\n",
    "    n_varvol_wins = (fitting_df['better_model'] == 'VarVol').sum()\n",
    "    n_weber_wins = (fitting_df['better_model'] == 'Weber').sum()\n",
    "    colors = ['#2ecc71', '#e74c3c']\n",
    "    explode = (0.05, 0.05)\n",
    "    ax.pie([n_varvol_wins, n_weber_wins], \n",
    "           labels=[f'VarVol\\n({n_varvol_wins})', f'Weber\\n({n_weber_wins})'],\n",
    "           autopct='%1.1f%%', colors=colors, explode=explode,\n",
    "           shadow=True, startangle=90)\n",
    "    ax.set_title('Which Model Wins? (BIC)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('participant_data/fig1_bic_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # ============================================================\n",
    "    # FIGURE 2: Fitted Parameter Distributions\n",
    "    # ============================================================\n",
    "    fig2, axes2 = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig2.suptitle('Figure 2: Fitted Parameter Distributions', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Panel 2a: Œ≤ comparison (both models)\n",
    "    ax = axes2[0, 0]\n",
    "    ax.hist(fitting_df['varvol_beta_softmax'], bins=15, alpha=0.6, label='VarVol Œ≤', color='#2ecc71')\n",
    "    ax.hist(fitting_df['weber_beta_softmax'], bins=15, alpha=0.6, label='Weber Œ≤', color='#e74c3c')\n",
    "    ax.axvline(fitting_df['varvol_beta_softmax'].mean(), color='#27ae60', linestyle='--', linewidth=2)\n",
    "    ax.axvline(fitting_df['weber_beta_softmax'].mean(), color='#c0392b', linestyle='--', linewidth=2)\n",
    "    ax.set_xlabel('Œ≤ (inverse temperature)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Softmax Œ≤ Distribution')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Panel 2b: Œ≤ scatter (VarVol vs Weber)\n",
    "    ax = axes2[0, 1]\n",
    "    ax.scatter(fitting_df['varvol_beta_softmax'], fitting_df['weber_beta_softmax'], \n",
    "               alpha=0.6, c='#3498db', s=50)\n",
    "    max_beta = max(fitting_df['varvol_beta_softmax'].max(), fitting_df['weber_beta_softmax'].max())\n",
    "    ax.plot([0, max_beta], [0, max_beta], 'k--', alpha=0.5, label='y=x')\n",
    "    r, p = stats.pearsonr(fitting_df['varvol_beta_softmax'], fitting_df['weber_beta_softmax'])\n",
    "    ax.set_xlabel('VarVol Œ≤')\n",
    "    ax.set_ylabel('Weber Œ≤')\n",
    "    ax.set_title(f'Œ≤ Correlation (r={r:.2f}, p={p:.3f})')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Panel 2c: Weber Œª distribution\n",
    "    ax = axes2[1, 0]\n",
    "    ax.hist(fitting_df['weber_lambdaa'], bins=15, color='#9b59b6', alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(fitting_df['weber_lambdaa'].mean(), color='black', linestyle='--', linewidth=2,\n",
    "               label=f'Mean: {fitting_df[\"weber_lambdaa\"].mean():.2f}')\n",
    "    ax.set_xlabel('Œª (Weber scaling)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Weber Œª Distribution')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Panel 2d: Weber Œº distribution\n",
    "    ax = axes2[1, 1]\n",
    "    ax.hist(fitting_df['weber_mu'], bins=15, color='#f39c12', alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(fitting_df['weber_mu'].mean(), color='black', linestyle='--', linewidth=2,\n",
    "               label=f'Mean: {fitting_df[\"weber_mu\"].mean():.3f}')\n",
    "    ax.set_xlabel('Œº (baseline noise)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Weber Œº Distribution')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('participant_data/fig2_parameters.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # ============================================================\n",
    "    # FIGURE 3: Log-Likelihood Comparison\n",
    "    # ============================================================\n",
    "    fig3, axes3 = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig3.suptitle('Figure 3: Log-Likelihood Analysis', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Panel 3a: Log-likelihood per participant\n",
    "    ax = axes3[0]\n",
    "    x = np.arange(n_participants)\n",
    "    ax.bar(x - width/2, fitting_df['varvol_log_lik'], width, label='VarVol', color='#2ecc71', alpha=0.8)\n",
    "    ax.bar(x + width/2, fitting_df['weber_log_lik'], width, label='Weber', color='#e74c3c', alpha=0.8)\n",
    "    ax.set_xlabel('Participant')\n",
    "    ax.set_ylabel('Log-Likelihood (higher = better)')\n",
    "    ax.set_title('Log-Likelihood per Participant')\n",
    "    ax.legend()\n",
    "    ax.set_xticks(x[::5])\n",
    "    \n",
    "    # Panel 3b: LL scatter\n",
    "    ax = axes3[1]\n",
    "    ax.scatter(fitting_df['varvol_log_lik'], fitting_df['weber_log_lik'], \n",
    "               alpha=0.6, c='#3498db', s=50)\n",
    "    min_ll = min(fitting_df['varvol_log_lik'].min(), fitting_df['weber_log_lik'].min())\n",
    "    max_ll = max(fitting_df['varvol_log_lik'].max(), fitting_df['weber_log_lik'].max())\n",
    "    ax.plot([min_ll, max_ll], [min_ll, max_ll], 'k--', alpha=0.5, label='y=x')\n",
    "    r, p = stats.pearsonr(fitting_df['varvol_log_lik'], fitting_df['weber_log_lik'])\n",
    "    ax.set_xlabel('VarVol Log-Likelihood')\n",
    "    ax.set_ylabel('Weber Log-Likelihood')\n",
    "    ax.set_title(f'LL Correlation (r={r:.2f})')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Panel 3c: ŒîLL distribution\n",
    "    ax = axes3[2]\n",
    "    delta_ll = fitting_df['varvol_log_lik'] - fitting_df['weber_log_lik']\n",
    "    ax.hist(delta_ll, bins=20, color='#1abc9c', alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "    ax.axvline(delta_ll.mean(), color='black', linestyle='-', linewidth=2,\n",
    "               label=f'Mean: {delta_ll.mean():.1f}')\n",
    "    ax.set_xlabel('ŒîLog-Likelihood (VarVol - Weber)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('ŒîLL Distribution\\n(positive = VarVol better raw fit)')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('participant_data/fig3_loglikelihood.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # ============================================================\n",
    "    # FIGURE 4: Model vs Human - Choice Prediction\n",
    "    # ============================================================\n",
    "    print(\"\\nüìä Computing choice match rates with fitted parameters...\")\n",
    "    \n",
    "    from pathlib import Path\n",
    "    \n",
    "    DATA_DIR = Path('participant_data/extended_csvs')\n",
    "    csv_files = sorted(DATA_DIR.glob('*.csv'))\n",
    "    \n",
    "    choice_match_results = []\n",
    "    \n",
    "    for i, row in fitting_df.iterrows():\n",
    "        participant_id = row['participant_id']\n",
    "        csv_file = DATA_DIR / f\"{participant_id}.csv\"\n",
    "        \n",
    "        if not csv_file.exists():\n",
    "            continue\n",
    "            \n",
    "        df = pd.read_csv(csv_file)\n",
    "        task = reconstruct_task_from_human_data(df)\n",
    "        human_choices = df['userChoice'].values.astype(int)\n",
    "        n_trials = len(human_choices)\n",
    "        \n",
    "        # Run VarVol with fitted parameters\n",
    "        varvol_agent = ForwardVaryingVolatilityAgent(\n",
    "            num_theta=FITTING_N_THETA,\n",
    "            num_state_particles=FITTING_N_STATE,\n",
    "            beta_softmax=row['varvol_beta_softmax'],\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        # Run Weber with fitted parameters\n",
    "        weber_agent = WeberImprecisionAgent(\n",
    "            num_theta=FITTING_N_THETA,\n",
    "            num_state_particles=FITTING_N_STATE,\n",
    "            beta_softmax=row['weber_beta_softmax'],\n",
    "            lambdaa=row['weber_lambdaa'],\n",
    "            mu=row['weber_mu'],\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        env_vv = TwoArmedBanditEnv(task)\n",
    "        env_wb = TwoArmedBanditEnv(task)\n",
    "        env_vv.reset()\n",
    "        env_wb.reset()\n",
    "        \n",
    "        varvol_choices = []\n",
    "        weber_choices = []\n",
    "        varvol_probs = []\n",
    "        weber_probs = []\n",
    "        \n",
    "        for t in range(n_trials):\n",
    "            stimulus = task.stimuli[t]\n",
    "            \n",
    "            # VarVol choice\n",
    "            vv_action, vv_probs = varvol_agent.act(stimulus)\n",
    "            varvol_choices.append(vv_action)\n",
    "            varvol_probs.append(vv_probs[human_choices[t]])\n",
    "            _, reward_vv, _ = env_vv.step(human_choices[t])\n",
    "            varvol_agent.observe(reward_vv)\n",
    "            \n",
    "            # Weber choice\n",
    "            wb_action, wb_probs = weber_agent.act(stimulus)\n",
    "            weber_choices.append(wb_action)\n",
    "            weber_probs.append(wb_probs[human_choices[t]])\n",
    "            _, reward_wb, _ = env_wb.step(human_choices[t])\n",
    "            weber_agent.observe(reward_wb)\n",
    "        \n",
    "        varvol_choices = np.array(varvol_choices)\n",
    "        weber_choices = np.array(weber_choices)\n",
    "        \n",
    "        # Compute metrics\n",
    "        varvol_match = np.mean(varvol_choices == human_choices)\n",
    "        weber_match = np.mean(weber_choices == human_choices)\n",
    "        human_accuracy = np.mean(human_choices == task.correct_actions)\n",
    "        varvol_accuracy = np.mean(varvol_choices == task.correct_actions)\n",
    "        weber_accuracy = np.mean(weber_choices == task.correct_actions)\n",
    "        model_agreement = np.mean(varvol_choices == weber_choices)\n",
    "        \n",
    "        choice_match_results.append({\n",
    "            'participant_id': participant_id,\n",
    "            'human_accuracy': human_accuracy,\n",
    "            'varvol_accuracy': varvol_accuracy,\n",
    "            'weber_accuracy': weber_accuracy,\n",
    "            'varvol_match_human': varvol_match,\n",
    "            'weber_match_human': weber_match,\n",
    "            'model_agreement': model_agreement,\n",
    "            'mean_varvol_prob': np.mean(varvol_probs),\n",
    "            'mean_weber_prob': np.mean(weber_probs),\n",
    "        })\n",
    "    \n",
    "    match_df = pd.DataFrame(choice_match_results)\n",
    "    \n",
    "    # Plot Figure 4\n",
    "    fig4, axes4 = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig4.suptitle('Figure 4: Model vs Human Performance', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Panel 4a: Choice match with human\n",
    "    ax = axes4[0, 0]\n",
    "    x = np.arange(len(match_df))\n",
    "    ax.bar(x - width/2, match_df['varvol_match_human'], width, label='VarVol', color='#2ecc71', alpha=0.8)\n",
    "    ax.bar(x + width/2, match_df['weber_match_human'], width, label='Weber', color='#e74c3c', alpha=0.8)\n",
    "    ax.axhline(0.5, color='gray', linestyle=':', label='Chance')\n",
    "    ax.set_xlabel('Participant')\n",
    "    ax.set_ylabel('Choice Match Rate')\n",
    "    ax.set_title('Model-Human Choice Agreement')\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Panel 4b: Accuracy comparison\n",
    "    ax = axes4[0, 1]\n",
    "    ax.scatter(match_df['human_accuracy'], match_df['varvol_accuracy'], \n",
    "               alpha=0.6, label='VarVol', color='#2ecc71', s=50)\n",
    "    ax.scatter(match_df['human_accuracy'], match_df['weber_accuracy'], \n",
    "               alpha=0.6, label='Weber', color='#e74c3c', s=50)\n",
    "    ax.plot([0.5, 1], [0.5, 1], 'k--', alpha=0.5)\n",
    "    ax.set_xlabel('Human Accuracy')\n",
    "    ax.set_ylabel('Model Accuracy')\n",
    "    ax.set_title('Accuracy: Model vs Human')\n",
    "    ax.legend()\n",
    "    ax.set_xlim(0.5, 1)\n",
    "    ax.set_ylim(0.5, 1)\n",
    "    \n",
    "    # Panel 4c: Choice match distribution\n",
    "    ax = axes4[0, 2]\n",
    "    ax.hist(match_df['varvol_match_human'], bins=15, alpha=0.6, label='VarVol', color='#2ecc71')\n",
    "    ax.hist(match_df['weber_match_human'], bins=15, alpha=0.6, label='Weber', color='#e74c3c')\n",
    "    ax.axvline(match_df['varvol_match_human'].mean(), color='#27ae60', linestyle='--', linewidth=2)\n",
    "    ax.axvline(match_df['weber_match_human'].mean(), color='#c0392b', linestyle='--', linewidth=2)\n",
    "    ax.set_xlabel('Choice Match Rate')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Distribution of Model-Human Match')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Panel 4d: Model agreement\n",
    "    ax = axes4[1, 0]\n",
    "    ax.hist(match_df['model_agreement'], bins=15, color='#9b59b6', alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(match_df['model_agreement'].mean(), color='black', linestyle='--', linewidth=2,\n",
    "               label=f'Mean: {match_df[\"model_agreement\"].mean():.2f}')\n",
    "    ax.set_xlabel('VarVol-Weber Agreement Rate')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Model-Model Agreement')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Panel 4e: Paired comparison\n",
    "    ax = axes4[1, 1]\n",
    "    ax.scatter(match_df['varvol_match_human'], match_df['weber_match_human'], \n",
    "               alpha=0.6, c='#3498db', s=50)\n",
    "    ax.plot([0.5, 1], [0.5, 1], 'k--', alpha=0.5, label='Equal')\n",
    "    t_stat, p_val = stats.ttest_rel(match_df['varvol_match_human'], match_df['weber_match_human'])\n",
    "    ax.set_xlabel('VarVol Match Rate')\n",
    "    ax.set_ylabel('Weber Match Rate')\n",
    "    ax.set_title(f'Model Comparison\\n(paired t={t_stat:.2f}, p={p_val:.3f})')\n",
    "    ax.legend()\n",
    "    ax.set_xlim(0.5, 1)\n",
    "    ax.set_ylim(0.5, 1)\n",
    "    \n",
    "    # Panel 4f: Summary boxplot\n",
    "    ax = axes4[1, 2]\n",
    "    data_to_plot = [match_df['human_accuracy'], match_df['varvol_accuracy'], \n",
    "                    match_df['weber_accuracy'], match_df['varvol_match_human'], \n",
    "                    match_df['weber_match_human']]\n",
    "    bp = ax.boxplot(data_to_plot, tick_labels=['Human\\nAcc', 'VarVol\\nAcc', 'Weber\\nAcc', \n",
    "                                                'VarVol\\nMatch', 'Weber\\nMatch'],\n",
    "                    patch_artist=True)\n",
    "    colors_box = ['#3498db', '#2ecc71', '#e74c3c', '#27ae60', '#c0392b']\n",
    "    for patch, color in zip(bp['boxes'], colors_box):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    ax.set_ylabel('Rate')\n",
    "    ax.set_title('Summary: Accuracy & Match Rates')\n",
    "    ax.set_ylim(0.4, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('participant_data/fig4_model_vs_human.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # ============================================================\n",
    "    # Print Summary Statistics\n",
    "    # ============================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìã FINAL SUMMARY STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nüéØ MODEL FIT (BIC - lower is better):\")\n",
    "    print(f\"   VarVol Mean BIC: {fitting_df['varvol_bic'].mean():.2f}\")\n",
    "    print(f\"   Weber Mean BIC:  {fitting_df['weber_bic'].mean():.2f}\")\n",
    "    print(f\"   ŒîBIC (VV-WB):    {fitting_df['delta_bic'].mean():.2f}\")\n",
    "    \n",
    "    print(\"\\nüéØ CHOICE PREDICTION (higher is better):\")\n",
    "    print(f\"   VarVol Match Human: {match_df['varvol_match_human'].mean():.1%}\")\n",
    "    print(f\"   Weber Match Human:  {match_df['weber_match_human'].mean():.1%}\")\n",
    "    \n",
    "    print(\"\\nüéØ TASK ACCURACY:\")\n",
    "    print(f\"   Human Accuracy:   {match_df['human_accuracy'].mean():.1%}\")\n",
    "    print(f\"   VarVol Accuracy:  {match_df['varvol_accuracy'].mean():.1%}\")\n",
    "    print(f\"   Weber Accuracy:   {match_df['weber_accuracy'].mean():.1%}\")\n",
    "    \n",
    "    print(\"\\nüéØ MODEL AGREEMENT:\")\n",
    "    print(f\"   VarVol-Weber Agreement: {match_df['model_agreement'].mean():.1%}\")\n",
    "    \n",
    "    # Statistical tests\n",
    "    print(\"\\nüéØ STATISTICAL TESTS:\")\n",
    "    t_bic, p_bic = stats.ttest_rel(fitting_df['varvol_bic'], fitting_df['weber_bic'])\n",
    "    t_match, p_match = stats.ttest_rel(match_df['varvol_match_human'], match_df['weber_match_human'])\n",
    "    print(f\"   BIC comparison (paired t-test): t={t_bic:.2f}, p={p_bic:.4f}\")\n",
    "    print(f\"   Choice match (paired t-test):   t={t_match:.2f}, p={p_match:.4f}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ All figures saved to participant_data/\")\n",
    "    \n",
    "    # Save match results\n",
    "    match_df.to_csv('participant_data/choice_match_results.csv', index=False)\n",
    "    print(\"   - choice_match_results.csv saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f92020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webermodelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
